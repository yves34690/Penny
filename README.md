# ğŸš€ ETL Pennylane Open-Source

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python](https://img.shields.io/badge/python-3.12+-blue.svg)](https://www.python.org/downloads/)
[![PostgreSQL](https://img.shields.io/badge/postgresql-15-blue.svg)](https://www.postgresql.org/)
[![Docker](https://img.shields.io/badge/docker-required-blue.svg)](https://www.docker.com/)
[![GitHub last commit](https://img.shields.io/github/last-commit/yves34690/Penny)](https://github.com/yves34690/Penny/commits/main)
[![GitHub stars](https://img.shields.io/github/stars/yves34690/Penny)](https://github.com/yves34690/Penny/stargazers)

---

## ğŸ¯ En une phrase

**Synchronisez automatiquement vos donnÃ©es Pennylane vers PostgreSQL toutes les 2 heures, transformez-les dans Jupyter Notebooks, et connectez Power BI pour des analyses ultra-rapides.**

---

## â­ Pourquoi ce projet ?

### Le problÃ¨me

Vous Ãªtes **expert-comptable**, **DAF** ou **data analyst** et vous rencontrez ces difficultÃ©s :

- **Actualisation Power BI = 30-60 minutes** Ã  cause des transformations lourdes dans Power Query
- **API Pennylane avec cache de 2 heures** pour les donnÃ©es comptables (grand livre, balance)
- **Difficile de personnaliser** les transformations sans maÃ®triser le langage M de Power Query
- **Impossible de rÃ©utiliser** les donnÃ©es transformÃ©es ailleurs (Excel, Tableau, Python)

### La solution

Ce projet ETL open-source rÃ©sout tous ces problÃ¨mes :

- âœ… **Actualisation Power BI = 2-5 minutes** (donnÃ©es prÃ©-traitÃ©es)
- âœ… **Transformations dans Jupyter Notebooks** (Python, facile Ã  personnaliser)
- âœ… **Synchronisation automatique toutes les 2 heures** (scheduler intelligent)
- âœ… **DonnÃ©es centralisÃ©es dans PostgreSQL** (rÃ©utilisables partout)
- âœ… **Architecture "Notebooks First"** : modifiez vos notebooks, le scheduler applique automatiquement

---

## ğŸ“Š Notre solution vs Power Query : Comparaison

| CritÃ¨re | **ETL Python + PostgreSQL** â­ | **Power Query Direct** |
|---------|-------------------------------|------------------------|
| â±ï¸ **Temps actualisation** | **2-5 min** | 30-60 min |
| ğŸ¯ **Performance** | â­â­â­â­â­ TrÃ¨s rapide | â­â­ Lent |
| ğŸ“Š **Gros volumes** | âœ… Millions de lignes | âŒ ~500k lignes max |
| ğŸ”„ **RÃ©utilisabilitÃ©** | âœ… Excel, Tableau, Python | âŒ Uniquement Power BI |
| ğŸ‘¥ **Collaboration** | âœ… Base centralisÃ©e | âŒ Fichier .pbix par personne |
| ğŸ¨ **Personnalisation** | âœ… Jupyter (visuel) | âš ï¸ Langage M (complexe) |
| ğŸ”§ **Maintenance** | âœ… 1 modification â†’ tous en profitent | âŒ Modifier chaque .pbix |
| ğŸ’¾ **Charge Power BI** | Minimale | TrÃ¨s Ã©levÃ©e |
| ğŸ“ˆ **ScalabilitÃ©** | â­â­â­â­â­ (serveur) | â­â­ (PC utilisateur) |
| ğŸ”„ **FrÃ©quence actualisation** | Toutes les 2h automatique | Manuel ou 8x/jour max |

**ğŸ’¡ Cas d'usage rÃ©el** : Cabinet avec 200k lignes comptables
- **Sans ETL** : 45 min d'actualisation, PC bloquÃ©
- **Avec ETL** : 3 min d'actualisation, PC libre
- **Gain** : **42 minutes Ã— 10 actualisations/jour = 7h gagnÃ©es/jour** â±ï¸

**ğŸ‘‰ Voir comparaison complÃ¨te** : [GUIDE_POWERBI_CONNEXION.md](GUIDE_POWERBI_CONNEXION.md#1-etl-pythonpostgresql-vs-power-query--quel-choix-)

---

## ğŸ“ Accessible Ã  TOUS

Ce projet est conÃ§u pour Ãªtre utilisable **sans connaissance en programmation**.

| Profil | Utilisation | Documentation |
|--------|-------------|---------------|
| ğŸ†• **DÃ©butant complet** | Guide pas-Ã -pas avec captures d'Ã©cran | ğŸ‘‰ **[DEMARRAGE_RAPIDE.md](DEMARRAGE_RAPIDE.md)** â­ |
| ğŸ‘” **Expert-comptable / DAF** | Personnaliser transformations via Jupyter Notebooks | [README_NOTEBOOK_SCHEDULER.md](README_NOTEBOOK_SCHEDULER.md) |
| ğŸ“Š **Data Analyst** | Modifier notebooks Python, ajouter colonnes calculÃ©es | [README_NOTEBOOK_SCHEDULER.md](README_NOTEBOOK_SCHEDULER.md) |
| ğŸ **DÃ©veloppeur Python** | Comprendre architecture, automatisation Docker | [GUIDE_AUTOMATION.md](GUIDE_AUTOMATION.md) |

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      PENNYLANE                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚   API REST       â”‚         â”‚  Data Sharing    â”‚        â”‚
â”‚  â”‚ (5 tables temps  â”‚         â”‚  (Redshift)      â”‚        â”‚
â”‚  â”‚  rÃ©el)           â”‚         â”‚  (comptabilitÃ©)  â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                              â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                  ğŸ“¥ EXTRACTION (2h)
                           â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   NOTEBOOK SCHEDULER         â”‚
            â”‚   (src/notebook_scheduler.py)â”‚
            â”‚   ExÃ©cute 16 notebooks       â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚      JUPYTER NOTEBOOKS                       â”‚
            â”‚      (data/API Publique/*.ipynb)             â”‚
            â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
            â”‚  â”‚ 1. Import_customers.ipynb           â”‚    â”‚
            â”‚  â”‚ 2. Import_analytical_ledger.ipynb   â”‚    â”‚
            â”‚  â”‚ 3. Import_general_ledger.ipynb      â”‚    â”‚
            â”‚  â”‚ ... 16 notebooks au total           â”‚    â”‚
            â”‚  â”‚                                      â”‚    â”‚
            â”‚  â”‚ ğŸ¨ VOUS MODIFIEZ ICI :              â”‚    â”‚
            â”‚  â”‚    - Ajout colonnes calculÃ©es       â”‚    â”‚
            â”‚  â”‚    - Transformations mÃ©tier         â”‚    â”‚
            â”‚  â”‚    - Filtres personnalisÃ©s          â”‚    â”‚
            â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                  ğŸ’¾ CHARGEMENT
                           â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   POSTGRESQL (Docker)        â”‚
            â”‚   Schema: pennylane          â”‚
            â”‚   12 tables transformÃ©es     â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
        â”‚   POWER BI    â”‚     â”‚   JUPYTER   â”‚
        â”‚   Desktop     â”‚     â”‚   Excel     â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Philosophie "Notebooks First"** :
1. Vous modifiez un notebook Jupyter (ajout colonnes, calculs)
2. Vous testez et visualisez immÃ©diatement
3. Le scheduler applique automatiquement vos changements toutes les 2h
4. Power BI se connecte aux donnÃ©es finales

**â¡ï¸ Aucune duplication de code !** Les notebooks sont la **seule source de vÃ©ritÃ©**.

---

## âš¡ Quick Start (5 minutes)

### PrÃ©requis

- **Windows, Mac ou Linux**
- **Python 3.12+** installÃ©
- **Docker Desktop** installÃ© ([Guide installation](GUIDE_INSTALLATION_DOCKER.md))

### ğŸ–¥ï¸ Comment ouvrir un terminal ?

**Pour exÃ©cuter les commandes ci-dessous, vous devez ouvrir un terminal :**

**Sur Windows** :
1. Appuyez sur la touche **Windows**
2. Tapez `PowerShell`
3. Cliquez sur **Windows PowerShell**
4. Une fenÃªtre bleue s'ouvre â†’ c'est votre terminal !

**Sur Mac** :
1. Appuyez sur **Cmd + Espace**
2. Tapez `Terminal`
3. Appuyez sur **EntrÃ©e**

**Sur Linux** :
- Appuyez sur **Ctrl + Alt + T**

---

### Installation

**Dans votre terminal**, tapez ces commandes une par une :

```bash
# 1. Cloner le projet
git clone https://github.com/yves34690/Penny.git
cd Penny

# 2. Installer dÃ©pendances Python
pip install -r requirements.txt

# 3. Configurer vos credentials
cp .env.example .env
# Ouvrez le fichier .env avec un Ã©diteur de texte (Notepad, VS Code)
# et ajoutez vos clÃ©s Pennylane

# 4. DÃ©marrer le systÃ¨me complet (PostgreSQL + Scheduler automatique)
docker-compose up -d

# 5. VÃ©rifier que tout est OK (optionnel mais recommandÃ©)
python verify_setup.py
```

**âœ… C'est tout !** Le systÃ¨me est maintenant **100% automatique** :
- âœ… PostgreSQL dÃ©marrÃ© sur le port 5433
- âœ… Scheduler automatique en cours d'exÃ©cution
- âœ… Synchronisation initiale en cours (8 min)
- âœ… Prochaine synchronisation dans 2 heures

**ğŸ“Š Suivre les logs en temps rÃ©el** :
```bash
docker-compose logs scheduler -f
```
*Appuyez sur Ctrl + C pour arrÃªter l'affichage*

**ğŸ”§ ArrÃªter le systÃ¨me** :
```bash
docker-compose down
```

**ğŸ”„ RedÃ©marrer aprÃ¨s un reboot du PC** :
```bash
cd C:\Penny && docker-compose up -d
```

**ğŸ¯ Pour plus de dÃ©tails sur l'automatisation** : Voir [GUIDE_AUTOMATION.md](GUIDE_AUTOMATION.md)

### ğŸ” VÃ©rification de la configuration

Le script `verify_setup.py` vÃ©rifie automatiquement :
- âœ… Fichier `.env` prÃ©sent et correctement configurÃ©
- âœ… Docker dÃ©marrÃ© (PostgreSQL + pgAdmin)
- âœ… Connexion PostgreSQL fonctionnelle
- âœ… Connexion Redshift (Data Warehouse Pennylane)
- âœ… Packages Python installÃ©s
- âœ… Notebooks prÃ©sents

**Si tout est vert**, vous pouvez lancer le scheduler en toute confiance !

### Connexion Power BI

```
Power BI Desktop
â†’ Obtenir les donnÃ©es
â†’ PostgreSQL
â†’ Serveur: localhost:5433
â†’ Base: pennylane_db
â†’ SÃ©lectionner schema "pennylane"
```

**Guide complet** : [GUIDE_POWERBI_CONNEXION.md](GUIDE_POWERBI_CONNEXION.md)

---

## ğŸ¤– Automatisation complÃ¨te avec Docker

### Mode automatique (RecommandÃ©)

**Une seule commande** pour tout dÃ©marrer :

```bash
docker-compose up -d
```

**Ce qui se passe automatiquement** :
1. âœ… PostgreSQL dÃ©marre (port 5433)
2. âœ… pgAdmin dÃ©marre ([http://localhost:5050](http://localhost:5050))
3. âœ… Le scheduler s'exÃ©cute immÃ©diatement (premiÃ¨re synchronisation)
4. âœ… Ensuite, synchronisation automatique toutes les 2 heures
5. âœ… RedÃ©marrage automatique en cas de crash ou reboot PC

**Aucune intervention nÃ©cessaire !** Le systÃ¨me tourne en arriÃ¨re-plan 24/7.

### VÃ©rifier que tout fonctionne

```bash
# Ã‰tat des conteneurs
docker-compose ps

# Logs en temps rÃ©el du scheduler
docker-compose logs scheduler -f

# Logs depuis le dernier dÃ©marrage
docker-compose logs scheduler --tail 100
```

**Sortie attendue** :
```
[DEMARRAGE] Notebook Scheduler Pennylane
[SYNC] DEBUT synchronisation
[OK] customers: 7 lignes exportÃ©es
[OK] analytical_ledger: 2251 lignes exportÃ©es
...
[SYNC] SuccÃ¨s: 12/12 | Erreurs: 0
[CRON] Prochaine exÃ©cution dans 2h
```

### Gestion du systÃ¨me

```bash
# ArrÃªter tout
docker-compose down

# RedÃ©marrer
docker-compose restart

# Forcer une synchronisation immÃ©diate
docker-compose restart scheduler
```

**ğŸ“– Documentation complÃ¨te** : [GUIDE_AUTOMATION.md](GUIDE_AUTOMATION.md)

---

## ğŸ“‚ Structure du projet (simplifiÃ©e)

```
Penny/
â”œâ”€â”€ ğŸ“„ .env.example                      # Template credentials (Ã  copier)
â”œâ”€â”€ ğŸ“„ .env                              # VOS secrets (jamais commitÃ©)
â”œâ”€â”€ ğŸ³ docker-compose.yml                # PostgreSQL + pgAdmin
â”œâ”€â”€ ğŸ“¦ requirements.txt                  # DÃ©pendances Python
â”‚
â”œâ”€â”€ ğŸ“ src/
â”‚   â”œâ”€â”€ ğŸ¤– notebook_scheduler.py         # â­ SCHEDULER PRINCIPAL (exÃ©cute notebooks)
â”‚   â””â”€â”€ ğŸ”Œ pennylane_api_client.py       # Client API Pennylane
â”‚
â”œâ”€â”€ ğŸ“ data/API Publique/
â”‚   â”œâ”€â”€ ğŸ““ Import_customers.ipynb        # ğŸ¨ NOTEBOOKS Ã€ PERSONNALISER
â”‚   â”œâ”€â”€ ğŸ““ Import_analytical_ledger.ipynb
â”‚   â”œâ”€â”€ ğŸ““ Import_general_ledger.ipynb
â”‚   â””â”€â”€ ... (16 notebooks au total)
â”‚
â”œâ”€â”€ ğŸ“ logs/
â”‚   â”œâ”€â”€ executed_notebooks/              # Historique exÃ©cutions notebooks
â”‚   â””â”€â”€ notebook_scheduler.log           # Logs du scheduler
â”‚
â””â”€â”€ ğŸ“š Documentation/
    â”œâ”€â”€ GUIDE_DEBUTANT.md                # ğŸ†• DÃ©marrage sans code
    â”œâ”€â”€ README_NOTEBOOK_SCHEDULER.md     # Architecture "Notebooks First"
    â”œâ”€â”€ CHOIX_SCHEDULER.md               # Notebook vs Unified scheduler
    â”œâ”€â”€ GUIDE_INSTALLATION_DOCKER.md     # Installer Docker pas-Ã -pas
    â””â”€â”€ GUIDE_POWERBI_CONNEXION.md       # Connecter Power BI + Comparaison ETL vs Power Query
```

**âœ¨ Seulement ~25 fichiers essentiels** (nettoyÃ© de tout superflu)

---

## ğŸ¯ Tables disponibles

| Table | Source | Description | Lignes (exemple) |
|-------|--------|-------------|------------------|
| **customers** | API REST | Clients | 7 |
| **suppliers** | API REST | Fournisseurs | 50 |
| **customer_invoices** | API REST | Factures clients | 12 |
| **supplier_invoices** | API REST | Factures fournisseurs | 273 |
| **bank_accounts** | API REST | Comptes bancaires | 5 |
| **analytical_ledger** | Redshift | Grand livre analytique | 2 251 |
| **general_ledger** | Redshift | Grand livre gÃ©nÃ©ral | 2 233 |
| **trial_balance** | Redshift | Balance gÃ©nÃ©rale | 163 |
| **bank_transactions** | Redshift | Transactions bancaires | 325 |
| **fiscal_years** | Redshift | Exercices fiscaux | 3 |
| **tax_declarations** | Redshift | DÃ©clarations fiscales | 12 |
| **vat_declarations** | Redshift | DÃ©clarations TVA | 18 |

**Total : 12 tables** (transformÃ©es avec colonnes calculÃ©es : PCG_1, PCG_2, Nature_Compte, Solde, etc.)

---

## ğŸ” SÃ©curitÃ© des credentials

### Architecture

- **`.env.example`** : Template public (committÃ© sur GitHub)
- **`.env`** : VOS secrets (ignorÃ© par Git, **jamais commitÃ©**)

### Variables obligatoires

Copiez `.env.example` vers `.env` et configurez :

```bash
# Pennylane API REST (5 tables temps rÃ©el)
PENNYLANE_API_TOKEN=votre_token_api_rest

# Pennylane Data Sharing (Redshift, 7 tables comptables)
PENNYLANE_DATA_SHARING_KEY=votre_cle_redshift
REDSHIFT_HOST=redshift-pennylane.123456789.eu-west-1.redshift.amazonaws.com
REDSHIFT_PORT=5439
REDSHIFT_DATABASE=votre_database
REDSHIFT_USER=votre_user

# PostgreSQL local (Docker)
POSTGRES_USER=pennylane_user
POSTGRES_PASSWORD=votre_mot_de_passe_securise
POSTGRES_DB=pennylane_db
POSTGRES_HOST=localhost
POSTGRES_PORT=5433
```

**âš ï¸ Important** : Le fichier `.gitignore` est configurÃ© pour **ne jamais commiter `.env`**.

---

## ğŸ¨ Personnaliser vos transformations

### Ã‰tape 1 : Ouvrir Jupyter

```bash
jupyter notebook
```

### Ã‰tape 2 : Modifier un notebook

Exemple : Ajouter une colonne dans `Import_analytical_ledger.ipynb`

```python
# Charger donnÃ©es brutes depuis Redshift
df = pd.read_sql("SELECT * FROM analytical_ledger", redshift_engine)

# ğŸ¨ AJOUTEZ VOS TRANSFORMATIONS ICI
df['montant_ht_euros'] = df['amount_cents'] / 100
df['trimestre'] = df['date'].dt.quarter
df['est_achat'] = df['PCG_1'] == '6'

# Sauvegarder dans PostgreSQL
df.to_sql('analytical_ledger', postgres_engine,
          schema='pennylane', if_exists='replace', index=False)
```

### Ã‰tape 3 : Tester immÃ©diatement

**Cell** â†’ **Run All** : Vous voyez le rÃ©sultat instantanÃ©ment

### Ã‰tape 4 : Le scheduler applique automatiquement

```bash
python src/notebook_scheduler.py
```

Ã€ chaque exÃ©cution (toutes les 2h), **votre notebook modifiÃ© est exÃ©cutÃ©** et PostgreSQL est mis Ã  jour.

**âœ… Aucune modification de code Python nÃ©cessaire !** Le scheduler dÃ©tecte automatiquement vos notebooks.

---

## ğŸ“Š Utilisation

### â­ Mode 1 : Docker Automatique (RecommandÃ© pour production)

```bash
# DÃ©marrer le systÃ¨me complet
docker-compose up -d
```

**Avantages** :
- âœ… Synchronisation automatique toutes les 2 heures
- âœ… RedÃ©marrage automatique en cas d'erreur
- âœ… RedÃ©marre au boot (si Docker Desktop configurÃ©)
- âœ… Pas besoin de garder un terminal ouvert

**Suivre l'exÃ©cution** :
```bash
docker-compose logs scheduler -f
```

**ArrÃªter** :
```bash
docker-compose down
```

ğŸ“– **Documentation complÃ¨te** : [GUIDE_AUTOMATION.md](GUIDE_AUTOMATION.md)

---

### Mode 2 : Python manuel (pour tests ou dÃ©veloppement)

#### 2a. Synchronisation unique

```bash
# ExÃ©cuter une fois tous les notebooks (8 min)
python src/notebook_scheduler.py
```

**ArrÃªter aprÃ¨s 1 synchro** : `Ctrl+C`

#### 2b. Synchronisation continue

```bash
# Lancer en continu (synchro toutes les 2h)
python src/notebook_scheduler.py
# Laisser tourner dans le terminal
```

**Logs en temps rÃ©el** :

```
[2025-10-15 14:00:00] ğŸš€ DÃ©marrage du Notebook Scheduler
[2025-10-15 14:00:05] âœ… customers - 7 lignes chargÃ©es
[2025-10-15 14:01:20] âœ… analytical_ledger - 2251 lignes chargÃ©es
...
[2025-10-15 14:08:15] ğŸ‰ Synchronisation complÃ¨te terminÃ©e (8m 15s)
[2025-10-15 14:08:15] â° Prochaine synchro : 2025-10-15 16:00:00
```

**ArrÃªter** : `Ctrl+C`

**InconvÃ©nient** : Vous devez laisser le terminal ouvert. Si vous le fermez, la synchro s'arrÃªte.

---

### Mode 3 : ExÃ©cuter un seul notebook

```bash
# Lancer Jupyter
jupyter notebook

# Ouvrir data/API Publique/Import_customers.ipynb
# Cell â†’ Run All
```

---

## ğŸ”§ Gestion PostgreSQL

### Interface graphique pgAdmin

**URL** : [http://localhost:5050](http://localhost:5050)

**Credentials** (par dÃ©faut) :
- Email : `admin@pennylane.local`
- Password : `admin`

### Connexion serveur PostgreSQL

1. **Clic droit** sur "Servers" â†’ **Register** â†’ **Server**
2. **Onglet General** :
   - Name : `Pennylane Local`
3. **Onglet Connection** :
   - Host : `postgres` (nom du conteneur Docker)
   - Port : `5432` (port interne Docker)
   - Database : `pennylane_db`
   - Username : `pennylane_user`
   - Password : (voir `.env`)

### RequÃªtes SQL utiles

```sql
-- Lister les tables
SELECT table_name,
       pg_size_pretty(pg_total_relation_size(quote_ident(table_name))) AS size
FROM information_schema.tables
WHERE table_schema = 'pennylane'
ORDER BY pg_total_relation_size(quote_ident(table_name)) DESC;

-- Voir un aperÃ§u
SELECT * FROM pennylane.analytical_ledger LIMIT 10;

-- Compter lignes
SELECT 'customers' AS table, COUNT(*) FROM pennylane.customers
UNION ALL
SELECT 'analytical_ledger', COUNT(*) FROM pennylane.analytical_ledger
UNION ALL
SELECT 'general_ledger', COUNT(*) FROM pennylane.general_ledger;
```

---

## ğŸ› DÃ©pannage

### ğŸ” PremiÃ¨re Ã©tape : Lancer le diagnostic automatique

```bash
python verify_setup.py
```

Ce script vÃ©rifie automatiquement tous les composants et affiche les erreurs Ã©ventuelles.

---

### âŒ Erreur : "Module 'papermill' not found"

**Solution** :
```bash
pip install -r requirements.txt
```

### âŒ Erreur : "Cannot connect to PostgreSQL"

**Diagnostic** :
```bash
docker ps
# Doit afficher 2 conteneurs "Up" (postgres + pgadmin)
```

**Solution** :
```bash
docker-compose restart
```

### âŒ Erreur API Pennylane : "Unauthorized"

**Solution** : VÃ©rifier `.env` :
- `PENNYLANE_API_TOKEN` (API REST)
- `PENNYLANE_DATA_SHARING_KEY` (Redshift)

### âŒ Notebook Ã©choue : "Table does not exist"

**Cause** : Mauvais credentials Redshift dans `.env`

**Solution** : Tester connexion Redshift manuellement :
```python
import psycopg2
import os
from dotenv import load_dotenv

load_dotenv()
conn = psycopg2.connect(
    host=os.getenv('REDSHIFT_HOST'),
    port=os.getenv('REDSHIFT_PORT'),
    database=os.getenv('REDSHIFT_DATABASE'),
    user=os.getenv('REDSHIFT_USER'),
    password=os.getenv('PENNYLANE_DATA_SHARING_KEY')
)
print("âœ… Connexion Redshift OK")
```

### Voir les logs complets

```bash
# Windows
type logs\notebook_scheduler.log

# Linux/Mac
cat logs/notebook_scheduler.log
```

---

## âš–ï¸ Notebook Scheduler vs Unified Scheduler

Ce projet propose **2 schedulers** :

| CritÃ¨re | **Notebook Scheduler** â­ | **Unified Scheduler** |
|---------|---------------------------|----------------------|
| **Source de vÃ©ritÃ©** | Notebooks Jupyter | Code Python dupliquÃ© |
| **Maintenance** | 1 seul endroit | 2 endroits (notebook + .py) |
| **Personnalisation** | â­â­â­â­â­ TrÃ¨s facile | â­â­â­ Moyen |
| **Public cible** | Tous (y compris non-devs) | DÃ©veloppeurs Python |
| **Performance** | ~10-12 min | ~8 min |

**ğŸ‘‰ RecommandÃ©** : **Notebook Scheduler** (philosophie de ce projet open-source)

**Voir comparaison complÃ¨te** : [CHOIX_SCHEDULER.md](CHOIX_SCHEDULER.md)

---

## ğŸ¤ Contribution

Ce projet est **open-source** et conÃ§u pour Ãªtre **forkable** facilement.

### Partager votre fork

1. **NE JAMAIS** commiter `.env` (vos secrets)
2. Mettre Ã  jour `.env.example` si nouvelles variables
3. Documenter vos transformations dans les notebooks

### DÃ©ploiement chez un client

```bash
# 1. Cloner
git clone https://github.com/votre-username/Penny.git
cd Penny

# 2. CrÃ©er .env
cp .env.example .env
nano .env  # Configurer credentials du client

# 3. DÃ©marrer
docker-compose up -d
pip install -r requirements.txt
python src/notebook_scheduler.py
```

### Ajouter un nouvel endpoint

1. **CrÃ©er notebook** : `data/API Publique/Import_nouvelle_table.ipynb`
2. **Le scheduler le dÃ©tecte automatiquement** (aucune modification code !)
3. **Tester** : ExÃ©cuter le notebook manuellement dans Jupyter
4. **DÃ©ployer** : Le scheduler l'inclura Ã  la prochaine synchro

---

## ğŸ“ Licence

**MIT License** - Libre d'utilisation, modification et redistribution.

Voir [LICENSE](LICENSE) pour dÃ©tails.

---

## ğŸ“ Support et communautÃ©

- **Documentation Pennylane API** : [pennylane.readme.io](https://pennylane.readme.io/)
- **Issues GitHub** : [github.com/yves34690/Penny/issues](https://github.com/yves34690/Penny/issues)
- **Documentation complÃ¨te** : Voir guides dans le projet

---

## ğŸŒŸ Remerciements

Projet crÃ©Ã© pour la **communautÃ© Pennylane** francophone.

Contributions bienvenues ! â­

---

**Auteur** : Yves Cloarec
**Version** : 3.0 (Architecture "Notebooks First")
**Date** : Octobre 2025
