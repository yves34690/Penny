# ğŸ”Œ Comprendre les API Pennylane

## ğŸ¯ Vue d'ensemble

Pennylane propose **2 mÃ©thodes d'accÃ¨s** aux donnÃ©es, chacune avec ses particularitÃ©s :

1. **API REST** (temps rÃ©el) â†’ Pour la gestion commerciale
2. **Data Sharing** (cache 2h) â†’ Pour la comptabilitÃ©

---

## ğŸ“Š Les 2 types d'accÃ¨s Pennylane

### 1ï¸âƒ£ API REST - Temps rÃ©el (5 tables)

**C'est quoi ?**
- API HTTP classique avec des endpoints REST
- AccÃ¨s **direct** Ã  la base de donnÃ©es en production

**Tables disponibles** :
- âœ… **Clients** (`customers`)
- âœ… **Fournisseurs** (`suppliers`)
- âœ… **Factures clients** (`customer_invoices`)
- âœ… **Factures fournisseurs** (`supplier_invoices`)
- âœ… **Comptes bancaires** (`bank_accounts`)

**CaractÃ©ristiques** :
- âš¡ **Temps rÃ©el** : Les donnÃ©es sont Ã  jour instantanÃ©ment
- ğŸš€ **Rapide** : RÃ©ponse en quelques millisecondes
- ğŸ“Š **Gestion commerciale** : Clients, factures en cours, etc.
- ğŸ”‘ **Token API** : `PENNYLANE_API_TOKEN`
- ğŸ”’ **Rate limit** : 5 requÃªtes/seconde (300/minute)

**Exemple d'utilisation** :
```python
# RÃ©cupÃ©rer la liste des clients
GET https://app.pennylane.com/api/v1/customers
Authorization: Bearer YOUR_API_TOKEN
```

**Pourquoi temps rÃ©el ?**
â†’ Ces donnÃ©es changent frÃ©quemment (nouvelles factures, nouveaux clients) et les utilisateurs ont besoin de les voir **immÃ©diatement**.

---

### 2ï¸âƒ£ Data Sharing (Redshift) - Cache 2 heures (7 tables)

**C'est quoi ?**
- AccÃ¨s **SQL direct** Ã  un Data Warehouse (Redshift)
- Les donnÃ©es sont **copiÃ©es** depuis la production toutes les 2 heures

**Tables disponibles** :
- âœ… **Grand livre** (`analytical_ledger`)
- âœ… **Grand livre gÃ©nÃ©ral** (`general_ledger`)
- âœ… **Balance gÃ©nÃ©rale** (`trial_balance`)
- âœ… **Exercices fiscaux** (`fiscal_years`)
- âœ… **DÃ©clarations TVA** (`vat_declarations`)
- âœ… **DÃ©clarations fiscales** (`tax_declarations`)
- âœ… **Transactions bancaires** (`bank_transactions`)

**CaractÃ©ristiques** :
- ğŸ• **Cache 2 heures** : Les donnÃ©es ne sont pas en temps rÃ©el
- ğŸ“š **DonnÃ©es comptables** : Grand livre, balance, TVA
- ğŸ” **Grosses volumÃ©tries** : Des millions de lignes
- ğŸ”‘ **Data Sharing Key** : `PENNYLANE_DATA_SHARING_KEY`
- ğŸ—„ï¸ **Redshift** : Base de donnÃ©es SQL optimisÃ©e pour l'analytique

**Exemple d'utilisation** :
```python
import psycopg2

# Connexion Ã  Redshift
conn = psycopg2.connect(
    host='pennylane-external.csqwamh5pldr.eu-west-1.redshift.amazonaws.com',
    port=5439,
    database='prod',
    user='u_289572',
    password=PENNYLANE_DATA_SHARING_KEY
)

# RequÃªte SQL
SELECT * FROM pennylane.analytical_ledger
WHERE date >= '2025-01-01'
```

**Pourquoi un cache de 2 heures ?**
â†’ Pour des raisons de **performance** et de **coÃ»t**.

---

## ğŸ¤” Pourquoi cette diffÃ©rence ?

### ProblÃ©matique technique

**1. Volume de donnÃ©es**

| Type | VolumÃ©trie typique | FrÃ©quence de consultation |
|------|-------------------|---------------------------|
| **Clients** | Centaines | Plusieurs fois par jour |
| **Grand livre** | **Millions de lignes** | Quelques fois par semaine |

**2. ComplexitÃ© des requÃªtes**

**API REST (temps rÃ©el)** :
```sql
-- Simple : rÃ©cupÃ©rer un client
SELECT * FROM customers WHERE id = 123
```
â†’ RequÃªte rapide, base de donnÃ©es peut gÃ©rer en temps rÃ©el.

**Data Sharing (cache 2h)** :
```sql
-- Complexe : balance comptable sur 5 ans
SELECT
    account_number,
    SUM(debit) - SUM(credit) as balance
FROM analytical_ledger
WHERE date BETWEEN '2020-01-01' AND '2025-12-31'
GROUP BY account_number
HAVING balance != 0
ORDER BY account_number
```
â†’ RequÃªte lourde, impossible en temps rÃ©el sans ralentir toute l'application.

---

## ğŸ’¡ La stratÃ©gie de Pennylane

### Pourquoi 2 systÃ¨mes ?

**API REST (temps rÃ©el)** â†’ Pour les **opÃ©rations courantes**
- CrÃ©er une facture
- Ajouter un client
- Consulter un paiement
â†’ **Impact utilisateur** : L'utilisateur attend une rÃ©ponse immÃ©diate

**Data Sharing (cache 2h)** â†’ Pour l'**analyse et le reporting**
- Balance comptable
- DÃ©clarations TVA
- Grand livre sur plusieurs annÃ©es
â†’ **Impact utilisateur** : L'utilisateur fait du reporting, 2h de dÃ©calage est acceptable

---

## ğŸ“ˆ Architecture technique

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PENNYLANE PRODUCTION                      â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Base de donnÃ©es   â”‚         â”‚   Base de donnÃ©es     â”‚  â”‚
â”‚  â”‚  OpÃ©rationnelle    â”‚         â”‚   Comptable           â”‚  â”‚
â”‚  â”‚                    â”‚         â”‚                       â”‚  â”‚
â”‚  â”‚  - Clients         â”‚         â”‚  - Grand livre        â”‚  â”‚
â”‚  â”‚  - Factures        â”‚         â”‚  - Balance            â”‚  â”‚
â”‚  â”‚  - Fournisseurs    â”‚         â”‚  - DÃ©clarations       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚           â”‚                                 â”‚               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                                 â”‚
            â”‚ Temps rÃ©el                      â”‚ Copie toutes les 2h
            â”‚                                 â”‚
            â–¼                                 â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   API REST    â”‚                â”‚  Data Warehouse â”‚
    â”‚               â”‚                â”‚   (Redshift)    â”‚
    â”‚  5 req/sec    â”‚                â”‚                 â”‚
    â”‚               â”‚                â”‚  Cache 2h       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                                 â”‚
            â”‚                                 â”‚
            â–¼                                 â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚           VOTRE ETL PENNY                         â”‚
    â”‚                                                   â”‚
    â”‚  - Synchronisation toutes les 2h                 â”‚
    â”‚  - 5 tables API REST (temps rÃ©el)                â”‚
    â”‚  - 7 tables Redshift (cache 2h)                  â”‚
    â”‚  - Export vers PostgreSQL                        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## â±ï¸ FrÃ©quence de mise Ã  jour

### Tableau rÃ©capitulatif

| Source | Tables | FraÃ®cheur | FrÃ©quence synchro Penny |
|--------|--------|-----------|------------------------|
| **API REST** | Clients, Fournisseurs, Factures, Comptes | **Temps rÃ©el** | Toutes les 2h |
| **Redshift** | Grand livre, Balance, TVA, Transactions | **Cache 2h** | Toutes les 2h |

**RÃ©sultat pour vous** :
- âœ… Vos donnÃ©es de gestion sont Ã  jour toutes les 2h
- âœ… Vos donnÃ©es comptables sont Ã  jour avec un dÃ©calage de 2-4h maximum
  - 2h (cache Pennylane) + 2h (synchro Penny) = 4h max

---

## ğŸ¯ Impact pratique

### Cas d'usage : PÃ©riode de clÃ´ture comptable

**ScÃ©nario** : Vous Ãªtes en clÃ´ture de mois, vous saisissez des Ã©critures dans Pennylane.

**Timeline** :
```
10h00 â†’ Vous saisissez une Ã©criture dans Pennylane
10h00 â†’ Ã‰criture visible dans Pennylane (interface web)
12h00 â†’ Pennylane copie les donnÃ©es vers Redshift (cache 2h)
12h00 â†’ Ã‰criture disponible via Data Sharing
14h00 â†’ Votre ETL Penny synchronise (toutes les 2h)
14h00 â†’ Ã‰criture visible dans Power BI
```

**DÃ©lai maximum** : 4 heures entre la saisie et Power BI

---

### Pourquoi c'est acceptable ?

**En compta, contrairement Ã  la gestion** :
- âœ… On ne fait pas 50 Ã©critures par heure
- âœ… On travaille sur des pÃ©riodes (mois, trimestre)
- âœ… On a besoin de **cohÃ©rence** plus que de temps rÃ©el
- âœ… Le reporting est fait en fin de journÃ©e/semaine/mois

**Exemple** :
- âŒ **Mauvais** pour : VÃ©rifier si un paiement client vient d'arriver (â†’ utiliser l'interface Pennylane)
- âœ… **Bon** pour : Analyser tous les paiements du mois dernier (â†’ utiliser Power BI avec Penny)

---

## ğŸ”„ Optimisation avec Penny

### Ce que fait Penny

**Sans Penny** :
- Power BI interroge directement Pennylane
- Temps de chargement : **30-60 minutes**
- Impossible de faire des analyses complexes

**Avec Penny** :
1. âœ… Penny synchronise toutes les 2h automatiquement
2. âœ… Les donnÃ©es sont **prÃ©-traitÃ©es** et stockÃ©es dans PostgreSQL
3. âœ… Power BI interroge PostgreSQL (local)
4. âœ… Temps de chargement : **2-5 minutes**

**BÃ©nÃ©fice** :
- ğŸš€ **12x plus rapide** (de 60 min Ã  5 min)
- ğŸ“Š PossibilitÃ© de faire des analyses complexes
- ğŸ”„ DonnÃ©es toujours synchronisÃ©es automatiquement

---

## ğŸ”‘ Les 2 tokens nÃ©cessaires

### Dans votre fichier .env

```env
# API REST (temps rÃ©el) - 5 tables
PENNYLANE_API_TOKEN=pk_live_abc123...

# Data Sharing (cache 2h) - 7 tables
PENNYLANE_DATA_SHARING_KEY=dsk_xyz789...
```

**Important** : Ce sont **2 tokens diffÃ©rents** !

---

## ğŸ“š OÃ¹ trouver ces tokens ?

### 1. API REST Token

1. Connectez-vous Ã  Pennylane
2. **ParamÃ¨tres** â†’ **DÃ©veloppeurs** â†’ **API**
3. Cliquez sur **"CrÃ©er un token"**
4. Copiez le token (`pk_live_...`)

### 2. Data Sharing Key

1. **ParamÃ¨tres** â†’ **DÃ©veloppeurs** â†’ **Data Sharing**
2. Copiez le **"Data Sharing Key"** (`dsk_...`)

---

## ğŸ“ En rÃ©sumÃ©

| Aspect | API REST | Data Sharing (Redshift) |
|--------|----------|------------------------|
| **Type de donnÃ©es** | Gestion commerciale | ComptabilitÃ© |
| **FraÃ®cheur** | âš¡ Temps rÃ©el | ğŸ• Cache 2h |
| **Tables** | 5 tables | 7 tables |
| **VolumÃ©trie** | Faible (milliers) | Ã‰levÃ©e (millions) |
| **Token** | `PENNYLANE_API_TOKEN` | `PENNYLANE_DATA_SHARING_KEY` |
| **Protocole** | HTTP REST | SQL (Redshift) |
| **Use case** | OpÃ©rations courantes | Reporting & Analytics |

---

## ğŸ’¡ Conseil pratique

**Quand actualiser vos donnÃ©es ?**

- ğŸ”„ **Toutes les 2h** (recommandÃ©) : Bon compromis entre fraÃ®cheur et charge serveur
- âš¡ **Toutes les 10 min** : Si vous Ãªtes en pleine saisie comptable intensive
- ğŸŒ™ **Une fois par nuit** : Si vous faites juste du reporting mensuel

**Comment changer la frÃ©quence ?**

Voir le [GUIDE_AUTOMATION.md](GUIDE_AUTOMATION.md) section "Puis-je changer la frÃ©quence d'actualisation ?"

---

## â“ FAQ

### "Pourquoi mes donnÃ©es comptables ne sont pas en temps rÃ©el ?"

**RÃ©ponse** : C'est une limitation de Pennylane. Le cache de 2h est imposÃ© par Pennylane pour des raisons de performance. Vos donnÃ©es ne peuvent pas Ãªtre plus fraÃ®ches que Ã§a.

### "Puis-je contourner le cache de 2h ?"

**RÃ©ponse** : Non, c'est impossible. C'est Pennylane qui contrÃ´le Ã§a. MÃªme si vous synchronisez toutes les 5 minutes, vous aurez toujours les mÃªmes donnÃ©es pendant 2 heures.

### "Les donnÃ©es de gestion sont-elles vraiment en temps rÃ©el ?"

**RÃ©ponse** : Oui, l'API REST donne des donnÃ©es temps rÃ©el. Mais **votre synchro Penny** tourne toutes les 2h, donc dans Power BI vous aurez un dÃ©calage maximum de 2h.

### "Comment avoir du temps rÃ©el dans Power BI ?"

**RÃ©ponse** :
1. Synchronisez plus souvent (toutes les 10 min au lieu de 2h)
2. Ou utilisez DirectQuery dans Power BI (mais ce sera plus lent)

---

## ğŸ”— Ressources

- **Documentation officielle Pennylane API** : [https://pennylane.readme.io/](https://pennylane.readme.io/)
- **Guide automatisation Penny** : [GUIDE_AUTOMATION.md](GUIDE_AUTOMATION.md)
- **Architecture du projet** : [README.md](README.md)

---

**Auteur** : Yves Cloarec
**Projet** : [Penny - ETL Open Source](https://github.com/yves34690/Penny)
**Date** : Octobre 2025
