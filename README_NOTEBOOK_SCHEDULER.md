# ğŸ““ Scheduler Orchestrateur de Notebooks

## ğŸ¯ Philosophie du projet

Ce projet adopte une approche **"Notebooks First"** oÃ¹ :
- âœ… **Notebooks = Source unique de vÃ©ritÃ©**
- âœ… Modifications dans notebooks = Automatiquement appliquÃ©es
- âœ… Visualisation interactive des donnÃ©es
- âœ… Personnalisation totale selon vos besoins

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    NOTEBOOKS JUPYTER                        â”‚
â”‚              (data/API Publique/*.ipynb)                    â”‚
â”‚                                                             â”‚
â”‚  ğŸ”§ Vous modifiez ici les transformations                  â”‚
â”‚  ğŸ‘ï¸  Vous visualisez les rÃ©sultats en temps rÃ©el           â”‚
â”‚  âœ… Vous testez avant d'automatiser                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â”‚ ExÃ©cution automatique toutes les 2h
                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            NOTEBOOK SCHEDULER (src/notebook_scheduler.py)   â”‚
â”‚                                                             â”‚
â”‚  ğŸ¤– ExÃ©cute vos notebooks modifiÃ©s                         â”‚
â”‚  ğŸ’¾ Sauvegarde rÃ©sultats dans data/outputs/                â”‚
â”‚  ğŸ“Š Exports vers PostgreSQL                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              POSTGRESQL (localhost:5433)                    â”‚
â”‚                     Schema: pennylane                       â”‚
â”‚                                                             â”‚
â”‚  ğŸ“Š 12 tables synchronisÃ©es                                 â”‚
â”‚  ğŸ”„ ActualisÃ©es toutes les 2 heures                         â”‚
â”‚  ğŸ”Œ ConnectÃ©es Ã  Power BI                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Workflow utilisateur

### 1ï¸âƒ£ **DÃ©veloppement** (Notebooks Jupyter)

```bash
# Ouvrir Jupyter
jupyter notebook
```

**Exemple** : Ajouter une colonne personnalisÃ©e dans [`Import_analytical_ledger.ipynb`](data/API Publique/Import_analytical_ledger.ipynb)

```python
# Cellule existante : Transformations
df['PCG_1'] = df['plan_item_number'].astype(str).str[:1]
df['PCG_2'] = df['plan_item_number'].astype(str).str[:2]
df['PCG_3'] = df['plan_item_number'].astype(str).str[:3]

# âœ¨ VOTRE NOUVELLE COLONNE (exemple)
df['Ratio_Debit_Credit'] = df['debit'] / df['credit'].replace(0, 1)

# Visualiser immÃ©diatement
df[['plan_item_number', 'PCG_1', 'Ratio_Debit_Credit']].head()
```

ğŸ’¡ **Avantage** : Vous voyez le rÃ©sultat instantanÃ©ment !

### 2ï¸âƒ£ **Test** (ExÃ©cution manuelle)

ExÃ©cutez toutes les cellules du notebook :
- `Cell > Run All`
- VÃ©rifiez que l'export PostgreSQL fonctionne
- VÃ©rifiez les donnÃ©es dans pgAdmin

### 3ï¸âƒ£ **Automatisation** (Scheduler)

```bash
# Lancer le scheduler
python src/notebook_scheduler.py
```

**Ce qu'il fait** :
- âœ… ExÃ©cute votre notebook modifiÃ© toutes les 2h
- âœ… Applique automatiquement vos transformations personnalisÃ©es
- âœ… Exporte vers PostgreSQL
- âœ… Sauvegarde l'historique dans `data/outputs/`

### 4ï¸âƒ£ **Power BI** (Visualisation)

Connectez Power BI Ã  PostgreSQL :
- **Host** : `localhost`
- **Port** : `5433`
- **Database** : `pennylane_db`
- **Schema** : `pennylane`

Vos colonnes personnalisÃ©es sont automatiquement disponibles ! ğŸ‰

---

## ğŸ“‹ Notebooks disponibles

### Tables API REST (Temps rÃ©el)
| Notebook | Table PostgreSQL | Description |
|----------|------------------|-------------|
| `Import_customers.ipynb` | `customers` | Clients |
| `Import_customer_invoices.ipynb` | `customer_invoices` | Factures clients |
| `Import_suppliers.ipynb` | `suppliers` | Fournisseurs |
| `Import_supplier_invoices.ipynb` | `supplier_invoices` | Factures fournisseurs |
| `Import_bank_transactions.ipynb` | `bank_transactions` | Transactions bancaires |

### Tables Redshift (ComptabilitÃ©)
| Notebook | Table PostgreSQL | Description |
|----------|------------------|-------------|
| `Import_analytical_ledger.ipynb` | `analytical_ledger` | Grand livre analytique â­ |
| `Import_general_ledger.ipynb` | `general_ledger` | Grand livre gÃ©nÃ©ral |
| `Import_trial_balance.ipynb` | `trial_balance` | Balance gÃ©nÃ©rale |
| `Import_bank_accounts.ipynb` | `bank_accounts` | Comptes bancaires |
| `Import_fiscal_years.ipynb` | `fiscal_years` | Exercices fiscaux |
| `Import_tax_declarations.ipynb` | `tax_declarations` | DÃ©clarations fiscales |
| `Import_vat_declarations.ipynb` | `vat_declarations` | DÃ©clarations TVA |

---

## ğŸ¨ Exemples de personnalisations

### Exemple 1 : Ajouter un indicateur mÃ©tier

**Dans `Import_customer_invoices.ipynb`** :

```python
# AprÃ¨s l'extraction des donnÃ©es
df['Delai_Paiement'] = (pd.to_datetime(df['deadline']) - pd.to_datetime(df['date'])).dt.days
df['Retard'] = df['Delai_Paiement'] > 30
```

**RÃ©sultat** : Colonnes `Delai_Paiement` et `Retard` automatiquement disponibles dans PostgreSQL et Power BI !

### Exemple 2 : Classifier les comptes comptables

**Dans `Import_analytical_ledger.ipynb`** :

```python
# Classification personnalisÃ©e selon votre plan comptable
def classifier_compte(numero):
    if numero.startswith('6'):
        return 'Charges'
    elif numero.startswith('7'):
        return 'Produits'
    elif numero.startswith('4'):
        return 'Tiers'
    else:
        return 'Autre'

df['Categorie_Compte'] = df['plan_item_number'].astype(str).apply(classifier_compte)
```

### Exemple 3 : Calculer des KPIs

**Dans `Import_bank_transactions.ipynb`** :

```python
# Calcul solde cumulÃ©
df = df.sort_values('date')
df['Solde_Cumule'] = df['amount'].cumsum()

# Identifier transactions importantes
df['Transaction_Importante'] = df['amount'].abs() > 1000
```

---

## ğŸ”§ Configuration

### Modifier la frÃ©quence d'exÃ©cution

**Fichier** : [`src/notebook_scheduler.py`](src/notebook_scheduler.py#L190)

```python
# Ligne 190 : Changer la frÃ©quence
schedule.every(2).hours.do(self.run_sync)  # Actuel : 2 heures

# Exemples :
schedule.every(30).minutes.do(self.run_sync)  # Toutes les 30 minutes
schedule.every(1).hours.do(self.run_sync)     # Toutes les heures
schedule.every().day.at("08:00").do(self.run_sync)  # Tous les jours Ã  8h
```

### Ajouter/Retirer des notebooks

**Fichier** : [`src/notebook_scheduler.py`](src/notebook_scheduler.py#L35)

```python
# Ligne 35 : Liste des notebooks
self.notebooks = [
    {
        'name': 'ma_table_custom',
        'notebook': 'Import_ma_table.ipynb',
        'description': 'Ma table personnalisÃ©e'
    },
    # ... autres notebooks
]
```

---

## ğŸ“Š Historique d'exÃ©cution

Chaque exÃ©cution crÃ©e un notebook de sortie :

```
data/outputs/
â”œâ”€â”€ analytical_ledger_20251015_123045.ipynb
â”œâ”€â”€ analytical_ledger_20251015_143045.ipynb  â† DerniÃ¨re exÃ©cution
â”œâ”€â”€ customers_20251015_123045.ipynb
â””â”€â”€ ...
```

**UtilitÃ©** :
- âœ… Audit : Voir exactement ce qui a Ã©tÃ© exÃ©cutÃ©
- âœ… Debug : Identifier erreurs dans l'historique
- âœ… Comparaison : Voir l'Ã©volution des donnÃ©es

---

## ğŸ†š Comparaison avec l'ancien scheduler

| CritÃ¨re | Ancien Scheduler<br>(`unified_scheduler.py`) | Nouveau Scheduler<br>(`notebook_scheduler.py`) |
|---------|----------------------------------------------|-----------------------------------------------|
| **Source de vÃ©ritÃ©** | Code Python dupliquÃ© | Notebooks Jupyter |
| **Modifications** | Modifier 2 endroits (notebook + py) | âœ… Modifier 1 seul endroit (notebook) |
| **Visualisation** | âŒ Pas de visualisation | âœ… Visualisation interactive |
| **Personnalisation** | CompÃ©tences Python requises | âœ… Utilisateurs non-devs OK |
| **Historique** | Logs texte uniquement | âœ… Notebooks exÃ©cutÃ©s complets |
| **Open-source** | Difficile Ã  forker/adapter | âœ… Facile Ã  personnaliser |
| **Performance** | ~8 min | ~10-12 min (lÃ©ger overhead) |

---

## â“ FAQ

### Puis-je utiliser les deux schedulers en parallÃ¨le ?

Non, ils feraient doublon. Choisissez l'un ou l'autre :
- **`notebook_scheduler.py`** â­ **RecommandÃ©** : FlexibilitÃ© maximale
- **`unified_scheduler.py`** : Performance optimale mais rigide

### Que se passe-t-il en cas d'erreur dans un notebook ?

Le scheduler :
1. âœ… Continue avec les notebooks suivants (pas de blocage)
2. âœ… Log l'erreur dans `logs/notebook_scheduler.log`
3. âœ… Sauvegarde le notebook avec erreur dans `data/outputs/`
4. âœ… Affiche clairement le bilan (X succÃ¨s, Y erreurs)

### Comment voir les logs en temps rÃ©el ?

```bash
# Windows
Get-Content logs\notebook_scheduler.log -Wait

# Linux/Mac
tail -f logs/notebook_scheduler.log
```

### Puis-je exÃ©cuter un seul notebook manuellement ?

Oui ! Deux options :

**Option 1** : Jupyter (manuel)
```bash
jupyter notebook
# Ouvrir le notebook â†’ Run All
```

**Option 2** : Papermill (CLI)
```bash
papermill "data/API Publique/Import_analytical_ledger.ipynb" "data/outputs/test.ipynb"
```

---

## ğŸ¯ Bonnes pratiques

### âœ… DO
- Testez vos modifications dans Jupyter avant d'automatiser
- Ajoutez des affichages (`display(df.head())`) pour visualiser
- Commentez vos transformations personnalisÃ©es
- Commitez rÃ©guliÃ¨rement vos notebooks sur Git

### âŒ DON'T
- Ne pas modifier `notebook_scheduler.py` directement (sauf config)
- Ne pas supprimer les cellules d'export PostgreSQL
- Ne pas renommer les notebooks sans mettre Ã  jour la config

---

## ğŸš€ Quick Start

```bash
# 1. Cloner le repo
git clone https://github.com/votre-username/Penny.git
cd Penny

# 2. Installer dÃ©pendances
pip install -r requirements.txt

# 3. Configurer .env
cp .env.example .env
# Ã‰diter .env avec vos credentials

# 4. DÃ©marrer PostgreSQL
docker-compose up -d

# 5. Tester un notebook manuellement
jupyter notebook
# Ouvrir Import_analytical_ledger.ipynb â†’ Run All

# 6. Lancer l'automatisation
python src/notebook_scheduler.py
```

**ğŸ‰ C'est tout ! Vos notebooks s'exÃ©cutent maintenant automatiquement toutes les 2h !**

---

## ğŸ¤ Contribution

Ce projet est open-source. Vous pouvez :
- Forker et adapter Ã  vos besoins
- Partager vos notebooks personnalisÃ©s
- Soumettre des amÃ©liorations via Pull Requests

---

## ğŸ“§ Support

- Documentation : [README.md](README.md)
- Issues : [GitHub Issues](https://github.com/votre-username/Penny/issues)
- CommunautÃ© Pennylane : [community.pennylane.com](https://community.pennylane.com)

---

**CrÃ©Ã© avec â¤ï¸ pour la communautÃ© Pennylane**
