{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97b44b8c",
   "metadata": {},
   "source": [
    "#Import du Grand livre#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2069820",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9db7dc",
   "metadata": {},
   "source": [
    "## Charger les variables d'environnement ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a60009ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement .env : ✓ Réussi\n"
     ]
    }
   ],
   "source": [
    "# Charger le .env depuis la racine du projet\n",
    "load_result = load_dotenv(dotenv_path='../../.env')\n",
    "print(f\"Chargement .env : {'✓ Réussi' if load_result else '✗ Échec'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed4931e",
   "metadata": {},
   "source": [
    "## Connexion Redshift Pennylane ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d6e9c290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connexion Redshift etablie\n"
     ]
    }
   ],
   "source": [
    "conn = psycopg2.connect(\n",
    "    host='pennylane-external.csqwamh5pldr.eu-west-1.redshift.amazonaws.com',\n",
    "    port=5439,\n",
    "    dbname='prod',\n",
    "    user='u_289572',\n",
    "    password=os.getenv('PENNYLANE_DATA_SHARING_KEY')\n",
    ")\n",
    "\n",
    "print(\"Connexion Redshift etablie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8b3c9b",
   "metadata": {},
   "source": [
    "## Fonction helper : Connexion auto-reconnect ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b68f6a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ycloa\\AppData\\Local\\Temp\\ipykernel_38764\\3220976796.py:6: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  pd.read_sql(\"SELECT 1;\", conn)\n",
      "C:\\Users\\ycloa\\AppData\\Local\\Temp\\ipykernel_38764\\3220976796.py:23: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(\"SELECT * FROM pennylane.customers LIMIT 1;\", get_active_connection())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test réussi : 1 ligne(s)\n"
     ]
    }
   ],
   "source": [
    "def get_active_connection():\n",
    "    \"\"\"Retourne une connexion active, la recrée si nécessaire\"\"\"\n",
    "    global conn\n",
    "    try:\n",
    "        # Test si la connexion est active\n",
    "        pd.read_sql(\"SELECT 1;\", conn)\n",
    "        return conn\n",
    "    except:\n",
    "        # Reconnexion si fermée\n",
    "        print(\"⟳ Reconnexion Redshift...\")\n",
    "        conn = psycopg2.connect(\n",
    "            host='pennylane-external.csqwamh5pldr.eu-west-1.redshift.amazonaws.com',\n",
    "            port=5439,\n",
    "            dbname='prod',\n",
    "            user='u_289572',\n",
    "            password=os.getenv('PENNYLANE_DATA_SHARING_KEY')\n",
    "        )\n",
    "        print(\"✓ Reconnecté\")\n",
    "        return conn\n",
    "\n",
    "# Utilisation : remplace \"conn\" par \"get_active_connection()\" dans tes requêtes\n",
    "# Exemple :\n",
    "df = pd.read_sql(\"SELECT * FROM pennylane.customers LIMIT 1;\", get_active_connection())\n",
    "print(f\"Test réussi : {len(df)} ligne(s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf99e98",
   "metadata": {},
   "source": [
    "## Liste table Grand Livre Pennylane ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32270b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ycloa\\AppData\\Local\\Temp\\ipykernel_38764\\248391769.py:11: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ general_ledger (23 colonnes)\n",
      "\n",
      "\n",
      "=== RÉSUMÉ: 1 tables accessibles ===\n",
      "    table_name  columns                                      column_list\n",
      "general_ledger       23 company_id, company_name, id, date, lettering...\n"
     ]
    }
   ],
   "source": [
    "# Tables Grand Livre Pennylane\n",
    "tables_extended = [\n",
    "    'general_ledger'\n",
    "]\n",
    "\n",
    "accessible_tables = []\n",
    "\n",
    "for table in tables_extended:\n",
    "    try:\n",
    "        query = f\"SELECT * FROM pennylane.{table} LIMIT 1;\"\n",
    "        df = pd.read_sql(query, conn)\n",
    "        accessible_tables.append({\n",
    "            'table_name': table,\n",
    "            'columns': len(df.columns),\n",
    "            'column_list': ', '.join(df.columns.tolist()[:5]) + '...'\n",
    "        })\n",
    "        print(f\"✓ {table} ({len(df.columns)} colonnes)\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(f\"\\n\\n=== RÉSUMÉ: {len(accessible_tables)} tables accessibles ===\")\n",
    "df_accessible = pd.DataFrame(accessible_tables)\n",
    "print(df_accessible.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c182e8",
   "metadata": {},
   "source": [
    "## Liste colonnes Grand Livre Pennylane ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82bca194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Table: pennylane.general_ledger\n",
      "============================================================\n",
      "Colonnes (23):\n",
      "   1. company_id\n",
      "   2. company_name\n",
      "   3. id\n",
      "   4. date\n",
      "   5. lettering\n",
      "   6. label\n",
      "   7. debit\n",
      "   8. credit\n",
      "   9. plan_item_number\n",
      "  10. plan_item_label\n",
      "  11. journal_code\n",
      "  12. journal_label\n",
      "  13. document_id\n",
      "  14. document_label\n",
      "  15. invoice_number\n",
      "  16. fec_pieceref\n",
      "  17. thirdparty_id\n",
      "  18. thirdparty_plan_item_number\n",
      "  19. thirdparty_plan_item_label\n",
      "  20. invoice_link\n",
      "  21. created_by\n",
      "  22. document_created_at\n",
      "  23. document_updated_at\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ycloa\\AppData\\Local\\Temp\\ipykernel_38764\\2518381739.py:8: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    }
   ],
   "source": [
    "# Afficher les colonnes grand livre\n",
    "tables_found = [\n",
    "    'general_ledger'\n",
    "]\n",
    "\n",
    "for table in tables_found:\n",
    "    query = f\"SELECT * FROM pennylane.{table} LIMIT 0;\"  # LIMIT 0 = structure seulement\n",
    "    df = pd.read_sql(query, conn)\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Table: pennylane.{table}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Colonnes ({len(df.columns)}):\")\n",
    "    for i, col in enumerate(df.columns, 1):\n",
    "        print(f\"  {i:2d}. {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28bf0ce",
   "metadata": {},
   "source": [
    "## Chargement des données du grand livre ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f77e3c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ycloa\\AppData\\Local\\Temp\\ipykernel_38764\\3220976796.py:6: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  pd.read_sql(\"SELECT 1;\", conn)\n",
      "C:\\Users\\ycloa\\AppData\\Local\\Temp\\ipykernel_38764\\867651531.py:3: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_general_ledger = pd.read_sql(query_gl, get_active_connection())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Données chargées : 2230 lignes, 23 colonnes\n"
     ]
    }
   ],
   "source": [
    "# Charger le grand livre complet\n",
    "query_gl = \"SELECT * FROM pennylane.general_ledger;\"\n",
    "df_general_ledger = pd.read_sql(query_gl, get_active_connection())\n",
    "\n",
    "print(f\"✓ Données chargées : {len(df_general_ledger)} lignes, {len(df_general_ledger.columns)} colonnes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2c816e",
   "metadata": {},
   "source": [
    "## Affichage des colonnes disponibles ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "23d18ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes disponibles :\n",
      "   1. company_id\n",
      "   2. company_name\n",
      "   3. id\n",
      "   4. date\n",
      "   5. lettering\n",
      "   6. label\n",
      "   7. debit\n",
      "   8. credit\n",
      "   9. plan_item_number\n",
      "  10. plan_item_label\n",
      "  11. journal_code\n",
      "  12. journal_label\n",
      "  13. document_id\n",
      "  14. document_label\n",
      "  15. invoice_number\n",
      "  16. fec_pieceref\n",
      "  17. thirdparty_id\n",
      "  18. thirdparty_plan_item_number\n",
      "  19. thirdparty_plan_item_label\n",
      "  20. invoice_link\n",
      "  21. created_by\n",
      "  22. document_created_at\n",
      "  23. document_updated_at\n"
     ]
    }
   ],
   "source": [
    "print(\"Colonnes disponibles :\")\n",
    "for i, col in enumerate(df_general_ledger.columns, 1):\n",
    "    print(f\"  {i:2d}. {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b1c8a4",
   "metadata": {},
   "source": [
    "## Suppresion de colonnes ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6856035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes supprimées : ['id', 'company_id', 'invoice_link', 'document_created_at', 'document_updated_at']\n",
      "\n",
      "✓ Résultat : 18 colonnes restantes\n",
      "Colonnes finales :\n",
      "['company_name', 'date', 'lettering', 'label', 'debit', 'credit', 'plan_item_number', 'plan_item_label', 'journal_code', 'journal_label', 'document_id', 'document_label', 'invoice_number', 'fec_pieceref', 'thirdparty_id', 'thirdparty_plan_item_number', 'thirdparty_plan_item_label', 'created_by']\n"
     ]
    }
   ],
   "source": [
    "# Colonnes à supprimer\n",
    "columns_to_drop = [\"id\", \"company_id\", \"invoice_link\", \"document_created_at\", \"document_updated_at\"]\n",
    "\n",
    "# Vérifier quelles colonnes existent réellement\n",
    "existing_cols = [col for col in columns_to_drop if col in df_general_ledger.columns]\n",
    "missing_cols = [col for col in columns_to_drop if col not in df_general_ledger.columns]\n",
    "\n",
    "print(f\"Colonnes supprimées : {existing_cols}\")\n",
    "if missing_cols:\n",
    "    print(f\"Colonnes inexistantes (ignorées) : {missing_cols}\")\n",
    "\n",
    "# Supprimer les colonnes\n",
    "df_general_ledger = df_general_ledger.drop(columns=existing_cols)\n",
    "\n",
    "print(f\"\\n✓ Résultat : {len(df_general_ledger.columns)} colonnes restantes\")\n",
    "print(f\"Colonnes finales :\\n{df_general_ledger.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cb4a3b",
   "metadata": {},
   "source": [
    "## Affichage type clonne ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "34268ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types de données des 18 colonnes :\n",
      "\n",
      "   1. company_name                   → object\n",
      "   2. date                           → object\n",
      "   3. lettering                      → float64\n",
      "   4. label                          → object\n",
      "   5. debit                          → float64\n",
      "   6. credit                         → float64\n",
      "   7. plan_item_number               → object\n",
      "   8. plan_item_label                → object\n",
      "   9. journal_code                   → object\n",
      "  10. journal_label                  → object\n",
      "  11. document_id                    → int64\n",
      "  12. document_label                 → object\n",
      "  13. invoice_number                 → object\n",
      "  14. fec_pieceref                   → object\n",
      "  15. thirdparty_id                  → float64\n",
      "  16. thirdparty_plan_item_number    → object\n",
      "  17. thirdparty_plan_item_label     → object\n",
      "  18. created_by                     → object\n"
     ]
    }
   ],
   "source": [
    "print(f\"Types de données des {len(df_general_ledger.columns)} colonnes :\\n\")\n",
    "for i, (col, dtype) in enumerate(df_general_ledger.dtypes.items(), 1):\n",
    "    print(f\"  {i:2d}. {col:<30} → {dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d5d0cd",
   "metadata": {},
   "source": [
    "## Conversion des types de colonnes ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b3a44998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Conversion effectuée\n",
      "\n",
      "Nouveaux types :\n",
      "   1. company_name                   → object\n",
      "   2. date                           → datetime64[ns]\n",
      "   3. lettering                      → object\n",
      "   4. label                          → object\n",
      "   5. debit                          → float64\n",
      "   6. credit                         → float64\n",
      "   7. plan_item_number               → object\n",
      "   8. plan_item_label                → object\n",
      "   9. journal_code                   → object\n",
      "  10. journal_label                  → object\n",
      "  11. document_id                    → object\n",
      "  12. document_label                 → object\n",
      "  13. invoice_number                 → object\n",
      "  14. fec_pieceref                   → object\n",
      "  15. thirdparty_id                  → object\n",
      "  16. thirdparty_plan_item_number    → object\n",
      "  17. thirdparty_plan_item_label     → object\n",
      "  18. created_by                     → object\n"
     ]
    }
   ],
   "source": [
    "# Conversion des types\n",
    "df_general_ledger = df_general_ledger.astype({\n",
    "    'date': 'datetime64[ns]',\n",
    "    'debit': 'float64',\n",
    "    'credit': 'float64'\n",
    "})\n",
    "\n",
    "# Convertir toutes les autres colonnes en string\n",
    "columns_to_string = [col for col in df_general_ledger.columns if col not in ['date', 'debit', 'credit']]\n",
    "df_general_ledger[columns_to_string] = df_general_ledger[columns_to_string].astype(str)\n",
    "\n",
    "print(\"✓ Conversion effectuée\\n\")\n",
    "print(\"Nouveaux types :\")\n",
    "for i, (col, dtype) in enumerate(df_general_ledger.dtypes.items(), 1):\n",
    "    print(f\"  {i:2d}. {col:<30} → {dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e1d25b",
   "metadata": {},
   "source": [
    "## Ajout des colonnes PCG (Plan Comptable Général) ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0542657a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Colonnes PCG ajoutées\n",
      "\n",
      "Aperçu des extractions :\n",
      "  plan_item_number PCG_1 PCG_2 PCG_3\n",
      "0         401OFFIC     4    40   401\n",
      "1         401OFFIC     4    40   401\n",
      "2             6064     6    60   606\n",
      "3             6064     6    60   606\n",
      "4             6227     6    62   622\n",
      "5         401GREFF     4    40   401\n",
      "6             6227     6    62   622\n",
      "7         401LEGAL     4    40   401\n",
      "8           445662     4    44   445\n",
      "9           445662     4    44   445\n",
      "\n",
      "✓ Total colonnes : 21\n"
     ]
    }
   ],
   "source": [
    "# Extraction des niveaux du plan comptable\n",
    "df_general_ledger['PCG_3'] = df_general_ledger['plan_item_number'].astype(str).str[:3]\n",
    "df_general_ledger['PCG_2'] = df_general_ledger['plan_item_number'].astype(str).str[:2]\n",
    "df_general_ledger['PCG_1'] = df_general_ledger['plan_item_number'].astype(str).str[:1]\n",
    "\n",
    "print(\"✓ Colonnes PCG ajoutées\\n\")\n",
    "\n",
    "# Vérification avec quelques exemples\n",
    "print(\"Aperçu des extractions :\")\n",
    "print(df_general_ledger[['plan_item_number', 'PCG_1', 'PCG_2', 'PCG_3']].head(10))\n",
    "\n",
    "print(f\"\\n✓ Total colonnes : {len(df_general_ledger.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccda486a",
   "metadata": {},
   "source": [
    "## Ajout Nature du compte ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0308db8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Colonne 'Nature_Compte' ajoutée (format texte)\n",
      "\n",
      "Type de la colonne : object\n",
      "\n",
      "Répartition par nature de compte :\n",
      "Nature_Compte\n",
      "Bilan       1753\n",
      "Resultat     477\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Aperçu :\n",
      "  plan_item_number PCG_1 Nature_Compte\n",
      "0         401OFFIC     4         Bilan\n",
      "1         401OFFIC     4         Bilan\n",
      "2             6064     6      Resultat\n",
      "3             6064     6      Resultat\n",
      "4             6227     6      Resultat\n",
      "5         401GREFF     4         Bilan\n",
      "6             6227     6      Resultat\n",
      "7         401LEGAL     4         Bilan\n",
      "8           445662     4         Bilan\n",
      "9           445662     4         Bilan\n"
     ]
    }
   ],
   "source": [
    "# Créer la colonne Nature Compte basée sur PCG_1 (format texte)\n",
    "df_general_ledger['Nature_Compte'] = df_general_ledger['PCG_1'].apply(\n",
    "    lambda x: 'Resultat' if x in ['6', '7'] else 'Bilan'\n",
    ").astype(str)\n",
    "\n",
    "print(\"✓ Colonne 'Nature_Compte' ajoutée (format texte)\\n\")\n",
    "\n",
    "# Vérification du type\n",
    "print(f\"Type de la colonne : {df_general_ledger['Nature_Compte'].dtype}\")\n",
    "\n",
    "# Vérification de la répartition\n",
    "print(\"\\nRépartition par nature de compte :\")\n",
    "print(df_general_ledger['Nature_Compte'].value_counts())\n",
    "\n",
    "print(\"\\nAperçu :\")\n",
    "print(df_general_ledger[['plan_item_number', 'PCG_1', 'Nature_Compte']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce42d24",
   "metadata": {},
   "source": [
    "## Ajout de la colonne Solde ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "01b2d588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Colonne 'Solde' ajoutée (format nombre)\n",
      "\n",
      "Type de la colonne : float64\n",
      "\n",
      "Statistiques sur la colonne Solde :\n",
      "count     2230.000000\n",
      "mean         3.673354\n",
      "std       1647.165441\n",
      "min     -10021.000000\n",
      "25%        -21.990000\n",
      "50%         -7.600000\n",
      "75%          5.620000\n",
      "max      10000.000000\n",
      "Name: Solde, dtype: float64\n",
      "\n",
      "Aperçu :\n",
      "  Nature_Compte   debit  credit   Solde\n",
      "0         Bilan    0.00   44.30  -44.30\n",
      "1         Bilan    0.00   36.66  -36.66\n",
      "2      Resultat   36.92    0.00  -36.92\n",
      "3      Resultat   30.54    0.00  -30.54\n",
      "4      Resultat  146.44    0.00 -146.44\n",
      "5         Bilan    0.00   11.23  -11.23\n",
      "6      Resultat    9.35    0.00   -9.35\n",
      "7         Bilan    0.00  175.73 -175.73\n",
      "8         Bilan   29.29    0.00   29.29\n",
      "9         Bilan    1.88    0.00    1.88\n"
     ]
    }
   ],
   "source": [
    "# Créer la colonne Solde basée sur Nature_Compte\n",
    "df_general_ledger['Solde'] = df_general_ledger.apply(\n",
    "    lambda row: row['debit'] - row['credit'] if row['Nature_Compte'] == 'Bilan' \n",
    "                else row['credit'] - row['debit'],\n",
    "    axis=1\n",
    ").astype(float)\n",
    "\n",
    "print(\"✓ Colonne 'Solde' ajoutée (format nombre)\\n\")\n",
    "\n",
    "# Vérification du type\n",
    "print(f\"Type de la colonne : {df_general_ledger['Solde'].dtype}\")\n",
    "\n",
    "# Statistiques sur le solde\n",
    "print(\"\\nStatistiques sur la colonne Solde :\")\n",
    "print(df_general_ledger['Solde'].describe())\n",
    "\n",
    "print(\"\\nAperçu :\")\n",
    "print(df_general_ledger[['Nature_Compte', 'debit', 'credit', 'Solde']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f7f398",
   "metadata": {},
   "source": [
    "## Connexion PostgreSQL local ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9f836437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Connexion PostgreSQL établie\n",
      "  Database: pennylane_data\n",
      "  User: pennylane_user\n",
      "  Port: 5433\n"
     ]
    }
   ],
   "source": [
    "# Connexion à PostgreSQL local (utilise les variables du .env)\n",
    "conn_pg = psycopg2.connect(\n",
    "    host=os.getenv('POSTGRES_HOST'),\n",
    "    port=int(os.getenv('POSTGRES_PORT')),\n",
    "    dbname=os.getenv('POSTGRES_DB'),\n",
    "    user=os.getenv('POSTGRES_USER'),\n",
    "    password=os.getenv('POSTGRES_PASSWORD')\n",
    ")\n",
    "\n",
    "print(\"✓ Connexion PostgreSQL établie\")\n",
    "print(f\"  Database: {os.getenv('POSTGRES_DB')}\")\n",
    "print(f\"  User: {os.getenv('POSTGRES_USER')}\")\n",
    "print(f\"  Port: {os.getenv('POSTGRES_PORT')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e7bf68",
   "metadata": {},
   "source": [
    "## Import des données dans PostgreSQL avec SQLAlchemy ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d4996d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Engine SQLAlchemy créé\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Créer un engine SQLAlchemy\n",
    "engine = create_engine(\n",
    "    f\"postgresql://{os.getenv('POSTGRES_USER')}:{os.getenv('POSTGRES_PASSWORD')}@{os.getenv('POSTGRES_HOST')}:{os.getenv('POSTGRES_PORT')}/{os.getenv('POSTGRES_DB')}\"\n",
    ")\n",
    "\n",
    "print(\"✓ Engine SQLAlchemy créé\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe19f14c",
   "metadata": {},
   "source": [
    "## Export du DataFrame vers PostgreSQL ##"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
