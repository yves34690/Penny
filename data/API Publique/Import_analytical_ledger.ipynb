{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d539ca54",
   "metadata": {},
   "source": [
    "# Import librairie #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51ff5c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6074b351",
   "metadata": {},
   "source": [
    "## Charger les variables d'environnement ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a1c4fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement .env : ✓ Réussi\n"
     ]
    }
   ],
   "source": [
    "# Charger le .env depuis la racine du projet\n",
    "from pathlib import Path\n",
    "dotenv_path = r'C:\\Penny\\.env'\n",
    "load_result = load_dotenv(dotenv_path=dotenv_path)\n",
    "print(f\"Chargement .env : {'[OK] Reussi' if load_result else '[ERREUR] Echec'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f309846a",
   "metadata": {},
   "source": [
    "## Connexion Redshift Pennylane ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6515e422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connexion Redshift etablie\n"
     ]
    }
   ],
   "source": [
    "conn = psycopg2.connect(\n",
    "    host='pennylane-external.csqwamh5pldr.eu-west-1.redshift.amazonaws.com',\n",
    "    port=5439,\n",
    "    dbname='prod',\n",
    "    user='u_289572',\n",
    "    password=os.getenv('PENNYLANE_DATA_SHARING_KEY')\n",
    ")\n",
    "\n",
    "print(\"Connexion Redshift etablie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202564c3",
   "metadata": {},
   "source": [
    "## Fonction helper : Connexion auto-reconnect ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11edf3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ycloa\\AppData\\Local\\Temp\\ipykernel_59680\\3220976796.py:6: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  pd.read_sql(\"SELECT 1;\", conn)\n",
      "C:\\Users\\ycloa\\AppData\\Local\\Temp\\ipykernel_59680\\3220976796.py:23: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(\"SELECT * FROM pennylane.customers LIMIT 1;\", get_active_connection())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test réussi : 1 ligne(s)\n"
     ]
    }
   ],
   "source": [
    "def get_active_connection():\n",
    "    \"\"\"Retourne une connexion active, la recrée si nécessaire\"\"\"\n",
    "    global conn\n",
    "    try:\n",
    "        # Test si la connexion est active\n",
    "        pd.read_sql(\"SELECT 1;\", conn)\n",
    "        return conn\n",
    "    except:\n",
    "        # Reconnexion si fermée\n",
    "        print(\"⟳ Reconnexion Redshift...\")\n",
    "        conn = psycopg2.connect(\n",
    "            host='pennylane-external.csqwamh5pldr.eu-west-1.redshift.amazonaws.com',\n",
    "            port=5439,\n",
    "            dbname='prod',\n",
    "            user='u_289572',\n",
    "            password=os.getenv('PENNYLANE_DATA_SHARING_KEY')\n",
    "        )\n",
    "        print(\"✓ Reconnecté\")\n",
    "        return conn\n",
    "\n",
    "# Utilisation : remplace \"conn\" par \"get_active_connection()\" dans tes requêtes\n",
    "# Exemple :\n",
    "df = pd.read_sql(\"SELECT * FROM pennylane.customers LIMIT 1;\", get_active_connection())\n",
    "print(f\"Test réussi : {len(df)} ligne(s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d455588b",
   "metadata": {},
   "source": [
    "## Liste table Grand Livre analytique ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b725116",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ycloa\\AppData\\Local\\Temp\\ipykernel_59680\\135546864.py:11: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ analytical_ledger (26 colonnes)\n",
      "\n",
      "\n",
      "=== RÉSUMÉ: 1 tables accessibles ===\n",
      "       table_name  columns                                      column_list\n",
      "analytical_ledger       26 id, company_id, company_name, date, lettering...\n"
     ]
    }
   ],
   "source": [
    "# Tables Grand Livre analytique SPennylane\n",
    "tables_extended = [\n",
    "    'analytical_ledger'\n",
    "]\n",
    "\n",
    "accessible_tables = []\n",
    "\n",
    "for table in tables_extended:\n",
    "    try:\n",
    "        query = f\"SELECT * FROM pennylane.{table} LIMIT 1;\"\n",
    "        df = pd.read_sql(query, conn)\n",
    "        accessible_tables.append({\n",
    "            'table_name': table,\n",
    "            'columns': len(df.columns),\n",
    "            'column_list': ', '.join(df.columns.tolist()[:5]) + '...'\n",
    "        })\n",
    "        print(f\"✓ {table} ({len(df.columns)} colonnes)\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(f\"\\n\\n=== RÉSUMÉ: {len(accessible_tables)} tables accessibles ===\")\n",
    "df_accessible = pd.DataFrame(accessible_tables)\n",
    "print(df_accessible.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a0600a",
   "metadata": {},
   "source": [
    "## Liste colonnes Grand Livre Analytique ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c0c4e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Table: pennylane.analytical_ledger\n",
      "============================================================\n",
      "Colonnes (26):\n",
      "   1. id\n",
      "   2. company_id\n",
      "   3. company_name\n",
      "   4. date\n",
      "   5. lettering\n",
      "   6. label\n",
      "   7. debit\n",
      "   8. credit\n",
      "   9. plan_item_number\n",
      "  10. plan_item_label\n",
      "  11. journal_code\n",
      "  12. journal_label\n",
      "  13. document_id\n",
      "  14. document_label\n",
      "  15. invoice_number\n",
      "  16. invoice_link\n",
      "  17. fec_pieceref\n",
      "  18. document_created_at\n",
      "  19. document_updated_at\n",
      "  20. thirdparty_id\n",
      "  21. thirdparty_plan_item_number\n",
      "  22. thirdparty_plan_item_label\n",
      "  23. tag_group\n",
      "  24. tag_label\n",
      "  25. analytical_code\n",
      "  26. tag_weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ycloa\\AppData\\Local\\Temp\\ipykernel_59680\\1164901612.py:8: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    }
   ],
   "source": [
    "# Afficher les colonnes analytical ledger\n",
    "tables_found = [\n",
    "    'analytical_ledger'\n",
    "]\n",
    "\n",
    "for table in tables_found:\n",
    "    query = f\"SELECT * FROM pennylane.{table} LIMIT 0;\"  # LIMIT 0 = structure seulement\n",
    "    df = pd.read_sql(query, conn)\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Table: pennylane.{table}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Colonnes ({len(df.columns)}):\")\n",
    "    for i, col in enumerate(df.columns, 1):\n",
    "        print(f\"  {i:2d}. {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa18d834",
   "metadata": {},
   "source": [
    "## Chargement des données du grand livre analytique ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c13497a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ycloa\\AppData\\Local\\Temp\\ipykernel_59680\\3220976796.py:6: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  pd.read_sql(\"SELECT 1;\", conn)\n",
      "C:\\Users\\ycloa\\AppData\\Local\\Temp\\ipykernel_59680\\1428549748.py:3: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_analytical_ledger = pd.read_sql(query_gl, get_active_connection())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Données chargées : 2248 lignes, 26 colonnes\n"
     ]
    }
   ],
   "source": [
    "# Charger le grand livre analytique complet\n",
    "query_gl = \"SELECT * FROM pennylane.analytical_ledger;\"\n",
    "df_analytical_ledger = pd.read_sql(query_gl, get_active_connection())\n",
    "\n",
    "print(f\"✓ Données chargées : {len(df_analytical_ledger)} lignes, {len(df_analytical_ledger.columns)} colonnes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d16a00",
   "metadata": {},
   "source": [
    "## Affichage des colonnes disponibles ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5d9b46d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes disponibles :\n",
      "   1. id\n",
      "   2. company_id\n",
      "   3. company_name\n",
      "   4. date\n",
      "   5. lettering\n",
      "   6. label\n",
      "   7. debit\n",
      "   8. credit\n",
      "   9. plan_item_number\n",
      "  10. plan_item_label\n",
      "  11. journal_code\n",
      "  12. journal_label\n",
      "  13. document_id\n",
      "  14. document_label\n",
      "  15. invoice_number\n",
      "  16. invoice_link\n",
      "  17. fec_pieceref\n",
      "  18. document_created_at\n",
      "  19. document_updated_at\n",
      "  20. thirdparty_id\n",
      "  21. thirdparty_plan_item_number\n",
      "  22. thirdparty_plan_item_label\n",
      "  23. tag_group\n",
      "  24. tag_label\n",
      "  25. analytical_code\n",
      "  26. tag_weight\n"
     ]
    }
   ],
   "source": [
    "print(\"Colonnes disponibles :\")\n",
    "for i, col in enumerate(df_analytical_ledger.columns, 1):\n",
    "    print(f\"  {i:2d}. {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d25ca71",
   "metadata": {},
   "source": [
    "## Suppresion de colonnes ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6199071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes supprimées : ['id', 'company_id', 'invoice_link', 'document_created_at', 'document_updated_at']\n",
      "\n",
      "✓ Résultat : 21 colonnes restantes\n",
      "Colonnes finales :\n",
      "['company_name', 'date', 'lettering', 'label', 'debit', 'credit', 'plan_item_number', 'plan_item_label', 'journal_code', 'journal_label', 'document_id', 'document_label', 'invoice_number', 'fec_pieceref', 'thirdparty_id', 'thirdparty_plan_item_number', 'thirdparty_plan_item_label', 'tag_group', 'tag_label', 'analytical_code', 'tag_weight']\n"
     ]
    }
   ],
   "source": [
    "# Colonnes à supprimer\n",
    "columns_to_drop = [\"id\", \"company_id\", \"invoice_link\", \"document_created_at\", \"document_updated_at\"]\n",
    "\n",
    "# Vérifier quelles colonnes existent réellement\n",
    "existing_cols = [col for col in columns_to_drop if col in df_analytical_ledger.columns]\n",
    "missing_cols = [col for col in columns_to_drop if col not in df_analytical_ledger.columns]\n",
    "\n",
    "print(f\"Colonnes supprimées : {existing_cols}\")\n",
    "if missing_cols:\n",
    "    print(f\"Colonnes inexistantes (ignorées) : {missing_cols}\")\n",
    "\n",
    "# Supprimer les colonnes\n",
    "df_analytical_ledger = df_analytical_ledger.drop(columns=existing_cols)\n",
    "\n",
    "print(f\"\\n✓ Résultat : {len(df_analytical_ledger.columns)} colonnes restantes\")\n",
    "print(f\"Colonnes finales :\\n{df_analytical_ledger.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adeb5ccf",
   "metadata": {},
   "source": [
    "## Affichage type clonne ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77e1efe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types de données des 21 colonnes :\n",
      "\n",
      "   1. company_name                   → object\n",
      "   2. date                           → object\n",
      "   3. lettering                      → float64\n",
      "   4. label                          → object\n",
      "   5. debit                          → float64\n",
      "   6. credit                         → float64\n",
      "   7. plan_item_number               → object\n",
      "   8. plan_item_label                → object\n",
      "   9. journal_code                   → object\n",
      "  10. journal_label                  → object\n",
      "  11. document_id                    → int64\n",
      "  12. document_label                 → object\n",
      "  13. invoice_number                 → object\n",
      "  14. fec_pieceref                   → object\n",
      "  15. thirdparty_id                  → float64\n",
      "  16. thirdparty_plan_item_number    → object\n",
      "  17. thirdparty_plan_item_label     → object\n",
      "  18. tag_group                      → object\n",
      "  19. tag_label                      → object\n",
      "  20. analytical_code                → object\n",
      "  21. tag_weight                     → float64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Types de données des {len(df_analytical_ledger.columns)} colonnes :\\n\")\n",
    "for i, (col, dtype) in enumerate(df_analytical_ledger.dtypes.items(), 1):\n",
    "    print(f\"  {i:2d}. {col:<30} → {dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a9523e",
   "metadata": {},
   "source": [
    "## Conversion des types de colonnes ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a97a0e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Conversion effectuée\n",
      "\n",
      "Nouveaux types :\n",
      "   1. company_name                   → object\n",
      "   2. date                           → datetime64[ns]\n",
      "   3. lettering                      → object\n",
      "   4. label                          → object\n",
      "   5. debit                          → float64\n",
      "   6. credit                         → float64\n",
      "   7. plan_item_number               → object\n",
      "   8. plan_item_label                → object\n",
      "   9. journal_code                   → object\n",
      "  10. journal_label                  → object\n",
      "  11. document_id                    → object\n",
      "  12. document_label                 → object\n",
      "  13. invoice_number                 → object\n",
      "  14. fec_pieceref                   → object\n",
      "  15. thirdparty_id                  → object\n",
      "  16. thirdparty_plan_item_number    → object\n",
      "  17. thirdparty_plan_item_label     → object\n",
      "  18. tag_group                      → object\n",
      "  19. tag_label                      → object\n",
      "  20. analytical_code                → object\n",
      "  21. tag_weight                     → object\n"
     ]
    }
   ],
   "source": [
    "# Conversion des types\n",
    "df_analytical_ledger = df_analytical_ledger.astype({\n",
    "    'date': 'datetime64[ns]',\n",
    "    'debit': 'float64',\n",
    "    'credit': 'float64'\n",
    "})\n",
    "\n",
    "# Convertir toutes les autres colonnes en string\n",
    "columns_to_string = [col for col in df_analytical_ledger.columns if col not in ['date', 'debit', 'credit']]\n",
    "df_analytical_ledger[columns_to_string] = df_analytical_ledger[columns_to_string].astype(str)\n",
    "\n",
    "print(\"✓ Conversion effectuée\\n\")\n",
    "print(\"Nouveaux types :\")\n",
    "for i, (col, dtype) in enumerate(df_analytical_ledger.dtypes.items(), 1):\n",
    "    print(f\"  {i:2d}. {col:<30} → {dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0df0a9",
   "metadata": {},
   "source": [
    "## Ajout des colonnes PCG (Plan Comptable Général) ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b186271e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Colonnes PCG ajoutées\n",
      "\n",
      "Aperçu des extractions :\n",
      "  plan_item_number PCG_1 PCG_2 PCG_3\n",
      "0           445662     4    44   445\n",
      "1             6227     6    62   622\n",
      "2           445662     4    44   445\n",
      "3         401LEGAL     4    40   401\n",
      "4         401GREFF     4    40   401\n",
      "5             6064     6    60   606\n",
      "6             6064     6    60   606\n",
      "7           445662     4    44   445\n",
      "8           445662     4    44   445\n",
      "9             6227     6    62   622\n",
      "\n",
      "✓ Total colonnes : 24\n"
     ]
    }
   ],
   "source": [
    "# Extraction des niveaux du plan comptable\n",
    "df_analytical_ledger['PCG_3'] = df_analytical_ledger['plan_item_number'].astype(str).str[:3]\n",
    "df_analytical_ledger['PCG_2'] = df_analytical_ledger['plan_item_number'].astype(str).str[:2]\n",
    "df_analytical_ledger['PCG_1'] = df_analytical_ledger['plan_item_number'].astype(str).str[:1]\n",
    "\n",
    "print(\"✓ Colonnes PCG ajoutées\\n\")\n",
    "\n",
    "# Vérification avec quelques exemples\n",
    "print(\"Aperçu des extractions :\")\n",
    "print(df_analytical_ledger[['plan_item_number', 'PCG_1', 'PCG_2', 'PCG_3']].head(10))\n",
    "\n",
    "print(f\"\\n✓ Total colonnes : {len(df_analytical_ledger.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d390ec49",
   "metadata": {},
   "source": [
    "## Ajout Nature du compte ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd98fc10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Colonne 'Nature_Compte' ajoutée (format texte)\n",
      "\n",
      "Type de la colonne : object\n",
      "\n",
      "Répartition par nature de compte :\n",
      "Nature_Compte\n",
      "Bilan       1767\n",
      "Resultat     481\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Aperçu :\n",
      "  plan_item_number PCG_1 Nature_Compte\n",
      "0           445662     4         Bilan\n",
      "1             6227     6      Resultat\n",
      "2           445662     4         Bilan\n",
      "3         401LEGAL     4         Bilan\n",
      "4         401GREFF     4         Bilan\n",
      "5             6064     6      Resultat\n",
      "6             6064     6      Resultat\n",
      "7           445662     4         Bilan\n",
      "8           445662     4         Bilan\n",
      "9             6227     6      Resultat\n"
     ]
    }
   ],
   "source": [
    "# Créer la colonne Nature Compte basée sur PCG_1 (format texte)\n",
    "df_analytical_ledger['Nature_Compte'] = df_analytical_ledger['PCG_1'].apply(\n",
    "    lambda x: 'Resultat' if x in ['6', '7'] else 'Bilan'\n",
    ").astype(str)\n",
    "\n",
    "print(\"✓ Colonne 'Nature_Compte' ajoutée (format texte)\\n\")\n",
    "\n",
    "# Vérification du type\n",
    "print(f\"Type de la colonne : {df_analytical_ledger['Nature_Compte'].dtype}\")\n",
    "\n",
    "# Vérification de la répartition\n",
    "print(\"\\nRépartition par nature de compte :\")\n",
    "print(df_analytical_ledger['Nature_Compte'].value_counts())\n",
    "\n",
    "print(\"\\nAperçu :\")\n",
    "print(df_analytical_ledger[['plan_item_number', 'PCG_1', 'Nature_Compte']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa592360",
   "metadata": {},
   "source": [
    "## Ajout de la colonne Solde ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea42a43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Colonne 'Solde' ajoutée (format nombre)\n",
      "\n",
      "Type de la colonne : float64\n",
      "\n",
      "Statistiques sur la colonne Solde :\n",
      "count     2248.000000\n",
      "mean        18.078995\n",
      "std       1679.535475\n",
      "min     -10021.000000\n",
      "25%        -21.990000\n",
      "50%         -7.600000\n",
      "75%          5.620000\n",
      "max      10000.000000\n",
      "Name: Solde, dtype: float64\n",
      "\n",
      "Aperçu :\n",
      "  Nature_Compte   debit  credit   Solde\n",
      "0         Bilan    7.38    0.00    7.38\n",
      "1      Resultat  146.44    0.00 -146.44\n",
      "2         Bilan   29.29    0.00   29.29\n",
      "3         Bilan    0.00  175.73 -175.73\n",
      "4         Bilan    0.00   11.23  -11.23\n",
      "5      Resultat   36.92    0.00  -36.92\n",
      "6      Resultat   30.54    0.00  -30.54\n",
      "7         Bilan    6.12    0.00    6.12\n",
      "8         Bilan    1.88    0.00    1.88\n",
      "9      Resultat    9.35    0.00   -9.35\n"
     ]
    }
   ],
   "source": [
    "# Créer la colonne Solde basée sur Nature_Compte\n",
    "df_analytical_ledger['Solde'] = df_analytical_ledger.apply(\n",
    "    lambda row: row['debit'] - row['credit'] if row['Nature_Compte'] == 'Bilan' \n",
    "                else row['credit'] - row['debit'],\n",
    "    axis=1\n",
    ").astype(float)\n",
    "\n",
    "print(\"✓ Colonne 'Solde' ajoutée (format nombre)\\n\")\n",
    "\n",
    "# Vérification du type\n",
    "print(f\"Type de la colonne : {df_analytical_ledger['Solde'].dtype}\")\n",
    "\n",
    "# Statistiques sur le solde\n",
    "print(\"\\nStatistiques sur la colonne Solde :\")\n",
    "print(df_analytical_ledger['Solde'].describe())\n",
    "\n",
    "print(\"\\nAperçu :\")\n",
    "print(df_analytical_ledger[['Nature_Compte', 'debit', 'credit', 'Solde']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebf24fa",
   "metadata": {},
   "source": [
    "## Connexion PostgreSQL local ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6674c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Connexion PostgreSQL établie\n",
      "  Database: pennylane_data\n",
      "  User: pennylane_user\n",
      "  Port: 5433\n"
     ]
    }
   ],
   "source": [
    "# Connexion à PostgreSQL local (utilise les variables du .env)\n",
    "conn_pg = psycopg2.connect(\n",
    "    host=os.getenv('POSTGRES_HOST'),\n",
    "    port=int(os.getenv('POSTGRES_PORT')),\n",
    "    dbname=os.getenv('POSTGRES_DB'),\n",
    "    user=os.getenv('POSTGRES_USER'),\n",
    "    password=os.getenv('POSTGRES_PASSWORD')\n",
    ")\n",
    "\n",
    "print(\"✓ Connexion PostgreSQL établie\")\n",
    "print(f\"  Database: {os.getenv('POSTGRES_DB')}\")\n",
    "print(f\"  User: {os.getenv('POSTGRES_USER')}\")\n",
    "print(f\"  Port: {os.getenv('POSTGRES_PORT')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b539455",
   "metadata": {},
   "source": [
    "## Import des données dans PostgreSQL avec SQLAlchemy ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acfccf8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Engine SQLAlchemy créé\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Créer un engine SQLAlchemy\n",
    "engine = create_engine(\n",
    "    f\"postgresql://{os.getenv('POSTGRES_USER')}:{os.getenv('POSTGRES_PASSWORD')}@{os.getenv('POSTGRES_HOST')}:{os.getenv('POSTGRES_PORT')}/{os.getenv('POSTGRES_DB')}\"\n",
    ")\n",
    "\n",
    "print(\"✓ Engine SQLAlchemy créé\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98166dd3",
   "metadata": {},
   "source": [
    "## Export du DataFrame vers PostgreSQL ##"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5904704b",
   "metadata": {},
   "source": [
    "## Export vers PostgreSQL local ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807c709c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export DataFrame vers PostgreSQL local\n",
    "df_analytical_ledger.to_sql(\n",
    "    name='analytical_ledger',\n",
    "    con=engine,\n",
    "    schema='pennylane',\n",
    "    if_exists='replace',\n",
    "    index=False,\n",
    "    method='multi',\n",
    "    chunksize=1000\n",
    ")\n",
    "\n",
    "print(f\"[OK] Table 'analytical_ledger' exportee : {len(df_analytical_ledger)} lignes\")\n",
    "\n",
    "# Fermer connexions\n",
    "conn.close()\n",
    "conn_pg.close()\n",
    "\n",
    "print(\"[OK] Connexions fermees\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
