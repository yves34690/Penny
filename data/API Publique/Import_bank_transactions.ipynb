{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0df5f824",
   "metadata": {},
   "source": [
    "# Import librairie #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f47ee6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e443c1f3",
   "metadata": {},
   "source": [
    "## Charger les variables d'environnement ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "114797b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement .env : ✓ Réussi\n"
     ]
    }
   ],
   "source": [
    "# Charger le .env depuis la racine du projet\n",
    "from pathlib import Path\n",
    "dotenv_path = r'C:\\Penny\\.env'\n",
    "load_result = load_dotenv(dotenv_path=dotenv_path)\n",
    "print(f\"Chargement .env : {'[OK] Reussi' if load_result else '[ERREUR] Echec'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964bd13d",
   "metadata": {},
   "source": [
    "## Connexion Redshift Pennylane ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "444e097f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connexion Redshift etablie\n"
     ]
    }
   ],
   "source": [
    "conn = psycopg2.connect(\n",
    "    host='pennylane-external.csqwamh5pldr.eu-west-1.redshift.amazonaws.com',\n",
    "    port=5439,\n",
    "    dbname='prod',\n",
    "    user='u_289572',\n",
    "    password=os.getenv('PENNYLANE_DATA_SHARING_KEY')\n",
    ")\n",
    "\n",
    "print(\"Connexion Redshift etablie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a71b935",
   "metadata": {},
   "source": [
    "## Fonction helper : Connexion auto-reconnect ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "955fa3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ycloa\\AppData\\Local\\Temp\\ipykernel_68128\\3220976796.py:6: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  pd.read_sql(\"SELECT 1;\", conn)\n",
      "C:\\Users\\ycloa\\AppData\\Local\\Temp\\ipykernel_68128\\3220976796.py:23: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(\"SELECT * FROM pennylane.customers LIMIT 1;\", get_active_connection())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test réussi : 1 ligne(s)\n"
     ]
    }
   ],
   "source": [
    "def get_active_connection():\n",
    "    \"\"\"Retourne une connexion active, la recrée si nécessaire\"\"\"\n",
    "    global conn\n",
    "    try:\n",
    "        # Test si la connexion est active\n",
    "        pd.read_sql(\"SELECT 1;\", conn)\n",
    "        return conn\n",
    "    except:\n",
    "        # Reconnexion si fermée\n",
    "        print(\"⟳ Reconnexion Redshift...\")\n",
    "        conn = psycopg2.connect(\n",
    "            host='pennylane-external.csqwamh5pldr.eu-west-1.redshift.amazonaws.com',\n",
    "            port=5439,\n",
    "            dbname='prod',\n",
    "            user='u_289572',\n",
    "            password=os.getenv('PENNYLANE_DATA_SHARING_KEY')\n",
    "        )\n",
    "        print(\"✓ Reconnecté\")\n",
    "        return conn\n",
    "\n",
    "# Utilisation : remplace \"conn\" par \"get_active_connection()\" dans tes requêtes\n",
    "# Exemple :\n",
    "df = pd.read_sql(\"SELECT * FROM pennylane.customers LIMIT 1;\", get_active_connection())\n",
    "print(f\"Test réussi : {len(df)} ligne(s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752c5b32",
   "metadata": {},
   "source": [
    "## Liste table Transactions Pennylane ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f58c2383",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ycloa\\AppData\\Local\\Temp\\ipykernel_68128\\1863438930.py:11: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ bank_transactions (18 colonnes)\n",
      "\n",
      "\n",
      "=== RÉSUMÉ: 1 tables accessibles ===\n",
      "       table_name  columns                                                      column_list\n",
      "bank_transactions       18 id, execution_date, company_id, account_name, thirdparty_name...\n"
     ]
    }
   ],
   "source": [
    "# Tables bank transactions Pennylane\n",
    "tables_extended = [\n",
    "    'bank_transactions'\n",
    "]\n",
    "\n",
    "accessible_tables = []\n",
    "\n",
    "for table in tables_extended:\n",
    "    try:\n",
    "        query = f\"SELECT * FROM pennylane.{table} LIMIT 1;\"\n",
    "        df = pd.read_sql(query, conn)\n",
    "        accessible_tables.append({\n",
    "            'table_name': table,\n",
    "            'columns': len(df.columns),\n",
    "            'column_list': ', '.join(df.columns.tolist()[:5]) + '...'\n",
    "        })\n",
    "        print(f\"✓ {table} ({len(df.columns)} colonnes)\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(f\"\\n\\n=== RÉSUMÉ: {len(accessible_tables)} tables accessibles ===\")\n",
    "df_accessible = pd.DataFrame(accessible_tables)\n",
    "print(df_accessible.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021599c0",
   "metadata": {},
   "source": [
    "## Liste colonnes Transactions Pennylane ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df19a452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Table: pennylane.bank_transactions\n",
      "============================================================\n",
      "Colonnes (18):\n",
      "   1. id\n",
      "   2. execution_date\n",
      "   3. company_id\n",
      "   4. account_name\n",
      "   5. thirdparty_name\n",
      "   6. thirdparty_id\n",
      "   7. label\n",
      "   8. amount_eur\n",
      "   9. outstanding_balance\n",
      "  10. currency\n",
      "  11. currency_amount\n",
      "  12. source\n",
      "  13. is_potential_duplicate\n",
      "  14. sftp_ebics_files_filename\n",
      "  15. sftp_ebics_files_created_at\n",
      "  16. accountants_view_status\n",
      "  17. proof_status\n",
      "  18. updated_at\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ycloa\\AppData\\Local\\Temp\\ipykernel_68128\\1145365256.py:8: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    }
   ],
   "source": [
    "# Afficher les colonnes bank transactions\n",
    "tables_found = [\n",
    "    'bank_transactions'\n",
    "]\n",
    "\n",
    "for table in tables_found:\n",
    "    query = f\"SELECT * FROM pennylane.{table} LIMIT 0;\"  # LIMIT 0 = structure seulement\n",
    "    df = pd.read_sql(query, conn)\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Table: pennylane.{table}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Colonnes ({len(df.columns)}):\")\n",
    "    for i, col in enumerate(df.columns, 1):\n",
    "        print(f\"  {i:2d}. {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a1c602",
   "metadata": {},
   "source": [
    "## Chargement des données transaction ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9c2d3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ycloa\\AppData\\Local\\Temp\\ipykernel_68128\\3220976796.py:6: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  pd.read_sql(\"SELECT 1;\", conn)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ycloa\\AppData\\Local\\Temp\\ipykernel_68128\\2826890354.py:3: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_bank_transactions = pd.read_sql(query_gl, get_active_connection())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Données chargées : 324 lignes, 18 colonnes\n"
     ]
    }
   ],
   "source": [
    "# Charger transactions\n",
    "query_gl = \"SELECT * FROM pennylane.bank_transactions;\"\n",
    "df_bank_transactions = pd.read_sql(query_gl, get_active_connection())\n",
    "\n",
    "print(f\"✓ Données chargées : {len(df_bank_transactions)} lignes, {len(df_bank_transactions.columns)} colonnes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4840c14e",
   "metadata": {},
   "source": [
    "## Affichage des colonnes disponibles ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bf41ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes disponibles :\n",
      "   1. id\n",
      "   2. execution_date\n",
      "   3. company_id\n",
      "   4. account_name\n",
      "   5. thirdparty_name\n",
      "   6. thirdparty_id\n",
      "   7. label\n",
      "   8. amount_eur\n",
      "   9. outstanding_balance\n",
      "  10. currency\n",
      "  11. currency_amount\n",
      "  12. source\n",
      "  13. is_potential_duplicate\n",
      "  14. sftp_ebics_files_filename\n",
      "  15. sftp_ebics_files_created_at\n",
      "  16. accountants_view_status\n",
      "  17. proof_status\n",
      "  18. updated_at\n"
     ]
    }
   ],
   "source": [
    "print(\"Colonnes disponibles :\")\n",
    "for i, col in enumerate(df_bank_transactions.columns, 1):\n",
    "    print(f\"  {i:2d}. {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21bebaf",
   "metadata": {},
   "source": [
    "## Suppresion de colonnes ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72f8f972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes supprimées : ['id', 'company_id', 'sftp_ebics_files_filename', 'sftp_ebics_files_created_at', 'updated_at']\n",
      "Colonnes inexistantes (ignorées) : ['created_at']\n",
      "\n",
      "✓ Résultat : 13 colonnes restantes\n",
      "Colonnes finales :\n",
      "['execution_date', 'account_name', 'thirdparty_name', 'thirdparty_id', 'label', 'amount_eur', 'outstanding_balance', 'currency', 'currency_amount', 'source', 'is_potential_duplicate', 'accountants_view_status', 'proof_status']\n"
     ]
    }
   ],
   "source": [
    "# Colonnes à supprimer\n",
    "columns_to_drop = [\"id\", \"company_id\",\"sftp_ebics_files_filename\",\"sftp_ebics_files_created_at\",\"created_at\", \"updated_at\"]\n",
    "\n",
    "# Vérifier quelles colonnes existent réellement\n",
    "existing_cols = [col for col in columns_to_drop if col in df_bank_transactions.columns]\n",
    "missing_cols = [col for col in columns_to_drop if col not in df_bank_transactions.columns]\n",
    "\n",
    "print(f\"Colonnes supprimées : {existing_cols}\")\n",
    "if missing_cols:\n",
    "    print(f\"Colonnes inexistantes (ignorées) : {missing_cols}\")\n",
    "\n",
    "# Supprimer les colonnes\n",
    "df_bank_transactions = df_bank_transactions.drop(columns=existing_cols)\n",
    "\n",
    "print(f\"\\n✓ Résultat : {len(df_bank_transactions.columns)} colonnes restantes\")\n",
    "print(f\"Colonnes finales :\\n{df_bank_transactions.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39871386",
   "metadata": {},
   "source": [
    "## Affichage type clonne ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c71dc623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Types de données des 13 colonnes :\n",
      "\n",
      "   1. execution_date                 → object\n",
      "   2. account_name                   → object\n",
      "   3. thirdparty_name                → object\n",
      "   4. thirdparty_id                  → float64\n",
      "   5. label                          → object\n",
      "   6. amount_eur                     → float64\n",
      "   7. outstanding_balance            → float64\n",
      "   8. currency                       → object\n",
      "   9. currency_amount                → float64\n",
      "  10. source                         → object\n",
      "  11. is_potential_duplicate         → bool\n",
      "  12. accountants_view_status        → object\n",
      "  13. proof_status                   → object\n"
     ]
    }
   ],
   "source": [
    "print(f\"Types de données des {len(df_bank_transactions.columns)} colonnes :\\n\")\n",
    "for i, (col, dtype) in enumerate(df_bank_transactions.dtypes.items(), 1):\n",
    "    print(f\"  {i:2d}. {col:<30} → {dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8219e7",
   "metadata": {},
   "source": [
    "## Conversion des types de colonnes ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e95fddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Conversion effectuée\n",
      "\n",
      "Nouveaux types :\n",
      "   1. execution_date                 → datetime64[ns]\n",
      "   2. account_name                   → object\n",
      "   3. thirdparty_name                → object\n",
      "   4. thirdparty_id                  → object\n",
      "   5. label                          → object\n",
      "   6. amount_eur                     → float64\n",
      "   7. outstanding_balance            → float64\n",
      "   8. currency                       → object\n",
      "   9. currency_amount                → float64\n",
      "  10. source                         → object\n",
      "  11. is_potential_duplicate         → object\n",
      "  12. accountants_view_status        → object\n",
      "  13. proof_status                   → object\n"
     ]
    }
   ],
   "source": [
    "# Conversion des types\n",
    "df_bank_transactions = df_bank_transactions.astype({\n",
    "    'amount_eur': 'float64',\n",
    "    'outstanding_balance': 'float64',\n",
    "    'execution_date': 'datetime64[ns]',\n",
    "    'currency_amount': 'float64'\n",
    "})\n",
    "\n",
    "# Convertir toutes les autres colonnes en string\n",
    "columns_to_string = [col for col in df_bank_transactions.columns if col not in ['amount_eur','outstanding_balance','execution_date','currency_amount']]\n",
    "df_bank_transactions[columns_to_string] = df_bank_transactions[columns_to_string].astype(str)\n",
    "\n",
    "print(\"✓ Conversion effectuée\\n\")\n",
    "print(\"Nouveaux types :\")\n",
    "for i, (col, dtype) in enumerate(df_bank_transactions.dtypes.items(), 1):\n",
    "    print(f\"  {i:2d}. {col:<30} → {dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017028e8",
   "metadata": {},
   "source": [
    "## Connexion PostgreSQL local ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e77d58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Connexion PostgreSQL établie\n",
      "  Database: pennylane_data\n",
      "  User: pennylane_user\n",
      "  Port: 5433\n"
     ]
    }
   ],
   "source": [
    "# Connexion à PostgreSQL local (utilise les variables du .env)\n",
    "conn_pg = psycopg2.connect(\n",
    "    host=os.getenv('POSTGRES_HOST'),\n",
    "    port=int(os.getenv('POSTGRES_PORT')),\n",
    "    dbname=os.getenv('POSTGRES_DB'),\n",
    "    user=os.getenv('POSTGRES_USER'),\n",
    "    password=os.getenv('POSTGRES_PASSWORD')\n",
    ")\n",
    "\n",
    "print(\"✓ Connexion PostgreSQL établie\")\n",
    "print(f\"  Database: {os.getenv('POSTGRES_DB')}\")\n",
    "print(f\"  User: {os.getenv('POSTGRES_USER')}\")\n",
    "print(f\"  Port: {os.getenv('POSTGRES_PORT')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d23dee",
   "metadata": {},
   "source": [
    "## Import des données dans PostgreSQL avec SQLAlchemy ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2baba10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Engine SQLAlchemy créé\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Créer un engine SQLAlchemy\n",
    "engine = create_engine(\n",
    "    f\"postgresql://{os.getenv('POSTGRES_USER')}:{os.getenv('POSTGRES_PASSWORD')}@{os.getenv('POSTGRES_HOST')}:{os.getenv('POSTGRES_PORT')}/{os.getenv('POSTGRES_DB')}\"\n",
    ")\n",
    "\n",
    "print(\"✓ Engine SQLAlchemy créé\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430d1916",
   "metadata": {},
   "source": [
    "## Export du DataFrame vers PostgreSQL ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4735a3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paramètres d'import\n",
    "table_name = 'bank_transactions'\n",
    "schema_name = 'pennylane'\n",
    "\n",
    "# Importer le DataFrame dans PostgreSQL\n",
    "print(f\"Import en cours de {len(df_bank_transactions)} lignes...\")\n",
    "\n",
    "df_bank_transactions.to_sql(\n",
    "    name=table_name,\n",
    "    con=engine,\n",
    "    schema=schema_name,\n",
    "    if_exists='replace',  # Options: 'fail', 'replace', 'append'\n",
    "    index=False,\n",
    "    method='multi',\n",
    "    chunksize=1000\n",
    ")\n",
    "\n",
    "print(f\"✓ Table '{schema_name}.{table_name}' importée avec succès !\")\n",
    "print(f\"  - {len(df_bank_transactions)} lignes\")\n",
    "print(f\"  - {len(df_bank_transactions.columns)} colonnes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
