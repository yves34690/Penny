{"config":{"lang":["fr"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"ETL Pennylane \u2192 PostgreSQL \u2192 Power BI","text":"<p>Bienvenue sur la documentation officielle de Penny !</p>"},{"location":"#presentation","title":"\ud83c\udfaf Pr\u00e9sentation","text":"<p>Penny est une solution ETL (Extract, Transform, Load) qui r\u00e9sout les probl\u00e8mes d'actualisation des donn\u00e9es Pennylane pour Power BI.</p>"},{"location":"#problemes-resolus","title":"Probl\u00e8mes r\u00e9solus","text":"Avant Apr\u00e8s Penny \u23f0 Actualisation API : 2 heures \u2705 10 minutes \ud83d\udc0c Actualisation Power BI : 30-60 min \u2705 2-5 minutes \ud83d\udcbe Transformations dans Power Query (lent) \u2705 Python + SQL (rapide) \ud83d\udcca Volume limit\u00e9 \u2705 Millions de lignes"},{"location":"#demarrage-rapide","title":"\ud83d\ude80 D\u00e9marrage rapide","text":"<pre><code># 1. Cloner\ngit clone https://github.com/yves34690/Penny.git\ncd Penny\n\n# 2. Configurer\ncp .env.example .env\nnano .env  # Ajouter PENNYLANE_API_KEY\n\n# 3. Installer\npip install -r requirements.txt\ndocker-compose up -d\n\n# 4. Lancer\ncd src &amp;&amp; python main.py full\n</code></pre>"},{"location":"#documentation","title":"\ud83d\udcda Documentation","text":"<ul> <li>Guide de d\u00e9marrage</li> <li>Guide utilisateur</li> <li>Configuration</li> <li>API Reference</li> <li>D\u00e9pannage</li> </ul>"},{"location":"#architecture","title":"\ud83c\udfd7\ufe0f Architecture","text":"<pre><code>graph LR\n    A[Pennylane API] --&gt;|10 min| B[Python ETL]\n    B --&gt;|Rate Limiting| C[PostgreSQL]\n    C --&gt; D[Jupyter]\n    C --&gt; E[Power BI]</code></pre>"},{"location":"#fonctionnalites","title":"\ud83d\udca1 Fonctionnalit\u00e9s","text":"<p>\u2705 Extraction automatique - Toutes les 10 minutes \u2705 Rate limiting - Respect limite API (5 req/sec) \u2705 Incr\u00e9mentiel - Seulement nouvelles donn\u00e9es \u2705 PostgreSQL - Stockage performant \u2705 S\u00e9curis\u00e9 - Gestion .env des secrets \u2705 Document\u00e9 - Guides complets \u2705 Open Source - MIT License</p>"},{"location":"#contribution","title":"\ud83e\udd1d Contribution","text":"<p>Les contributions sont les bienvenues ! Voir CONTRIBUTING.md</p>"},{"location":"#licence","title":"\ud83d\udcdd Licence","text":"<p>MIT License - Voir LICENSE</p> <p>Cr\u00e9\u00e9 avec \u2764\ufe0f par yves34690</p>"},{"location":"api-reference/","title":"API Reference","text":"<p>Documentation des modules Python de Penny.</p>"},{"location":"api-reference/#config_loader","title":"config_loader","text":"<p>Module de chargement de configuration depuis <code>.env</code> et <code>config.json</code>.</p>"},{"location":"api-reference/#load_full_config","title":"<code>load_full_config()</code>","text":"<p>Charge la configuration compl\u00e8te.</p> <pre><code>from config_loader import load_full_config\n\nconfig = load_full_config()\n</code></pre> <p>Returns: <code>Dict[str, Any]</code> - Configuration compl\u00e8te</p> <p>Raises: <code>ValueError</code> si configuration invalide</p>"},{"location":"api-reference/#get_envkey-default-required","title":"<code>get_env(key, default, required)</code>","text":"<p>R\u00e9cup\u00e8re une variable d'environnement.</p> <pre><code>from config_loader import get_env\n\napi_key = get_env('PENNYLANE_API_KEY', required=True)\n</code></pre> <p>Parameters: - <code>key</code> (str): Nom de la variable - <code>default</code> (Any): Valeur par d\u00e9faut - <code>required</code> (bool): Si True, erreur si absent</p> <p>Returns: Valeur de la variable</p>"},{"location":"api-reference/#pennylane_api","title":"pennylane_api","text":"<p>Client API Pennylane avec rate limiting.</p>"},{"location":"api-reference/#pennylaneapi","title":"<code>PennylaneAPI</code>","text":"<p>Client pour l'API Pennylane.</p> <pre><code>from pennylane_api import PennylaneAPI\n\napi = PennylaneAPI(\n    api_key=\"votre_cle\",\n    base_url=\"https://app.pennylane.com/api/external/v1\",\n    rate_limit=4.5\n)\n</code></pre>"},{"location":"api-reference/#methodes","title":"M\u00e9thodes","text":""},{"location":"api-reference/#get_paginated_dataendpoint-params-max_pages","title":"<code>get_paginated_data(endpoint, params, max_pages)</code>","text":"<p>R\u00e9cup\u00e8re toutes les donn\u00e9es pagin\u00e9es.</p> <pre><code>data = api.get_paginated_data('/customer_invoices')\n</code></pre> <p>Parameters: - <code>endpoint</code> (str): Endpoint API - <code>params</code> (Dict, optional): Param\u00e8tres suppl\u00e9mentaires - <code>max_pages</code> (int, optional): Limite de pages</p> <p>Returns: <code>List[Dict]</code> - Tous les enregistrements</p>"},{"location":"api-reference/#get_incremental_dataendpoint-last_sync_date-date_field","title":"<code>get_incremental_data(endpoint, last_sync_date, date_field)</code>","text":"<p>Extraction incr\u00e9mentielle.</p> <pre><code>from datetime import datetime\n\nlast_sync = datetime(2025, 1, 1)\ndata = api.get_incremental_data(\n    '/customer_invoices',\n    last_sync,\n    'updated_at'\n)\n</code></pre> <p>Returns: <code>List[Dict]</code> - Enregistrements modifi\u00e9s</p>"},{"location":"api-reference/#test_connection","title":"<code>test_connection()</code>","text":"<p>Teste la connexion API.</p> <pre><code>if api.test_connection():\n    print(\"Connexion OK\")\n</code></pre> <p>Returns: <code>bool</code></p>"},{"location":"api-reference/#database","title":"database","text":"<p>Gestion base de donn\u00e9es PostgreSQL.</p>"},{"location":"api-reference/#postgresdatabase","title":"<code>PostgresDatabase</code>","text":"<p>Gestionnaire PostgreSQL avec context manager.</p> <pre><code>from database import PostgresDatabase\n\nconfig = load_full_config()\n\nwith PostgresDatabase(config) as db:\n    db.load_dataframe(df, 'table_name')\n</code></pre>"},{"location":"api-reference/#methodes_1","title":"M\u00e9thodes","text":""},{"location":"api-reference/#load_dataframedf-table_name-if_exists-batch_size","title":"<code>load_dataframe(df, table_name, if_exists, batch_size)</code>","text":"<p>Charge un DataFrame dans PostgreSQL.</p> <pre><code>rows = db.load_dataframe(\n    df,\n    'invoices',\n    if_exists='replace',\n    batch_size=1000\n)\n</code></pre> <p>Parameters: - <code>df</code> (pd.DataFrame): DataFrame \u00e0 charger - <code>table_name</code> (str): Nom de la table - <code>if_exists</code> (str): 'replace', 'append', 'fail' - <code>batch_size</code> (int): Taille des batchs</p> <p>Returns: <code>int</code> - Nombre de lignes ins\u00e9r\u00e9es</p>"},{"location":"api-reference/#upsert_dataframedf-table_name-conflict_columns","title":"<code>upsert_dataframe(df, table_name, conflict_columns)</code>","text":"<p>Upsert (INSERT ON CONFLICT UPDATE).</p> <pre><code>db.upsert_dataframe(\n    df,\n    'invoices',\n    conflict_columns=['id']\n)\n</code></pre>"},{"location":"api-reference/#get_last_sync_datetable_name","title":"<code>get_last_sync_date(table_name)</code>","text":"<p>Date de derni\u00e8re synchronisation.</p> <pre><code>last_sync = db.get_last_sync_date('invoices')\n</code></pre> <p>Returns: <code>datetime</code> ou <code>None</code></p>"},{"location":"api-reference/#transformations","title":"transformations","text":"<p>Transformations basiques des donn\u00e9es.</p>"},{"location":"api-reference/#datatransformer","title":"<code>DataTransformer</code>","text":"<p>Applique transformations minimales.</p> <pre><code>from transformations import DataTransformer\n\ntransformer = DataTransformer(config)\ndf_clean = transformer.basic_transform(df, 'invoices')\n</code></pre>"},{"location":"api-reference/#methodes_2","title":"M\u00e9thodes","text":""},{"location":"api-reference/#basic_transformdf-table_name","title":"<code>basic_transform(df, table_name)</code>","text":"<p>Nettoyage basique.</p> <pre><code>df_clean = transformer.basic_transform(df, 'invoices')\n</code></pre> <p>Transformations appliqu\u00e9es: - Normalisation noms colonnes (snake_case) - Suppression doublons</p>"},{"location":"api-reference/#normalize_column_namesdf","title":"<code>normalize_column_names(df)</code>","text":"<p>Normalise noms de colonnes (statique).</p> <pre><code>df = DataTransformer.normalize_column_names(df)\n</code></pre>"},{"location":"api-reference/#main","title":"main","text":"<p>Script ETL principal.</p>"},{"location":"api-reference/#mainmode","title":"<code>main(mode)</code>","text":"<p>Ex\u00e9cution ETL.</p> <pre><code>from main import main\n\nmain(mode='full')      # Extraction compl\u00e8te\nmain(mode='incremental')  # Incr\u00e9mentiel\n</code></pre> <p>Parameters: - <code>mode</code> (str): 'full' ou 'incremental'</p>"},{"location":"api-reference/#scheduler","title":"scheduler","text":"<p>Planificateur automatique.</p>"},{"location":"api-reference/#etlscheduler","title":"<code>ETLScheduler</code>","text":"<p>Planificateur pour ex\u00e9cutions r\u00e9p\u00e9t\u00e9es.</p> <pre><code>from scheduler import ETLScheduler\n\nscheduler = ETLScheduler(interval_minutes=10)\nscheduler.start()\n</code></pre>"},{"location":"api-reference/#methodes_3","title":"M\u00e9thodes","text":""},{"location":"api-reference/#start","title":"<code>start()</code>","text":"<p>D\u00e9marre le planificateur.</p>"},{"location":"api-reference/#stop","title":"<code>stop()</code>","text":"<p>Arr\u00eate le planificateur.</p>"},{"location":"api-reference/#exemples-complets","title":"Exemples complets","text":""},{"location":"api-reference/#extraction-complete","title":"Extraction compl\u00e8te","text":"<pre><code>from config_loader import load_full_config\nfrom pennylane_api import PennylaneAPI\nfrom database import PostgresDatabase\nimport pandas as pd\n\n# Configuration\nconfig = load_full_config()\n\n# API\napi = PennylaneAPI(\n    api_key=config['pennylane_api']['api_key'],\n    base_url=config['pennylane_api']['base_url']\n)\n\n# Extraction\ndata = api.get_paginated_data('/customer_invoices')\ndf = pd.DataFrame(data)\n\n# Chargement\nwith PostgresDatabase(config) as db:\n    db.load_dataframe(df, 'invoices', if_exists='replace')\n</code></pre>"},{"location":"api-reference/#extraction-incrementielle","title":"Extraction incr\u00e9mentielle","text":"<pre><code>from datetime import datetime\n\n# R\u00e9cup\u00e9rer derni\u00e8re sync\nwith PostgresDatabase(config) as db:\n    last_sync = db.get_last_sync_date('invoices')\n\n    # Extraction incr\u00e9mentielle\n    data = api.get_incremental_data(\n        '/customer_invoices',\n        last_sync,\n        'updated_at'\n    )\n\n    if data:\n        df = pd.DataFrame(data)\n        db.load_dataframe(df, 'invoices', if_exists='append')\n</code></pre>"},{"location":"architecture/","title":"Architecture technique","text":""},{"location":"architecture/#vue-densemble","title":"Vue d'ensemble","text":"<pre><code>graph TB\n    A[Pennylane API] --&gt;|HTTP REST| B[Python ETL]\n    B --&gt;|Rate Limiting 5/s| C{Scheduler}\n    C --&gt;|10 min| D[Extract]\n    D --&gt; E[Transform]\n    E --&gt; F[Load]\n    F --&gt; G[(PostgreSQL)]\n    G --&gt; H[Jupyter Notebook]\n    G --&gt; I[Power BI]\n    G --&gt; J[pgAdmin]</code></pre>"},{"location":"architecture/#composants","title":"Composants","text":""},{"location":"architecture/#1-extraction-pennylane_apipy","title":"1. Extraction (pennylane_api.py)","text":"<p>R\u00f4le: Communication avec API Pennylane</p> <p>Fonctionnalit\u00e9s: - Rate limiting (5 requ\u00eates/seconde) - Gestion pagination automatique - Retry avec backoff exponentiel - Extraction incr\u00e9mentielle</p> <pre><code>api = PennylaneAPI(api_key, base_url, rate_limit=4.5)\ndata = api.get_paginated_data('/customer_invoices')\n</code></pre>"},{"location":"architecture/#2-transformation-transformationspy","title":"2. Transformation (transformations.py)","text":"<p>R\u00f4le: Nettoyage basique</p> <p>Transformations: - Normalisation noms colonnes (snake_case) - Suppression doublons - Nettoyage espaces</p> <p>Transformations m\u00e9tier</p> <p>Les transformations avanc\u00e9es sont faites dans Jupyter Notebook</p>"},{"location":"architecture/#3-chargement-databasepy","title":"3. Chargement (database.py)","text":"<p>R\u00f4le: Stockage PostgreSQL</p> <p>Fonctionnalit\u00e9s: - Cr\u00e9ation automatique tables - Batch insert optimis\u00e9 - Upsert (INSERT ON CONFLICT) - Logs ex\u00e9cution - M\u00e9tadonn\u00e9es synchronisation</p>"},{"location":"architecture/#4-orchestration-mainpy","title":"4. Orchestration (main.py)","text":"<p>R\u00f4le: Coordination ETL</p> <p>Modes: - <code>full</code>: Extraction compl\u00e8te - <code>incremental</code>: Nouvelles donn\u00e9es uniquement</p>"},{"location":"architecture/#5-planification-schedulerpy","title":"5. Planification (scheduler.py)","text":"<p>R\u00f4le: Ex\u00e9cution automatique</p> <p>Param\u00e8tres: - Intervalle configurable (d\u00e9faut: 10 min) - Mode incr\u00e9mentiel - Logs d\u00e9taill\u00e9s</p>"},{"location":"architecture/#flux-de-donnees","title":"Flux de donn\u00e9es","text":""},{"location":"architecture/#extraction-complete-full","title":"Extraction compl\u00e8te (full)","text":"<pre><code>sequenceDiagram\n    participant U as User\n    participant M as main.py\n    participant A as PennylaneAPI\n    participant D as PostgresDatabase\n\n    U-&gt;&gt;M: python main.py full\n    M-&gt;&gt;A: get_paginated_data()\n    loop Pour chaque page\n        A-&gt;&gt;A: wait_for_rate_limit()\n        A-&gt;&gt;Pennylane: GET /endpoint?page=X\n        Pennylane--&gt;&gt;A: {data: [...]}\n    end\n    A--&gt;&gt;M: List[Dict]\n    M-&gt;&gt;M: basic_transform()\n    M-&gt;&gt;D: load_dataframe(if_exists='replace')\n    D-&gt;&gt;D: CREATE TABLE\n    D-&gt;&gt;D: INSERT batch\n    D--&gt;&gt;M: rows_loaded\n    M-&gt;&gt;D: log_etl_execution()</code></pre>"},{"location":"architecture/#extraction-incrementielle-incremental","title":"Extraction incr\u00e9mentielle (incremental)","text":"<pre><code>sequenceDiagram\n    participant S as scheduler.py\n    participant M as main.py\n    participant D as PostgresDatabase\n    participant A as PennylaneAPI\n\n    S-&gt;&gt;M: main('incremental')\n    M-&gt;&gt;D: get_last_sync_date()\n    D--&gt;&gt;M: datetime(2025-01-07 10:00)\n    M-&gt;&gt;A: get_incremental_data(last_sync)\n    A-&gt;&gt;Pennylane: GET /endpoint?filter[updated_at]=gte:2025-01-07\n    Pennylane--&gt;&gt;A: {data: [new_records]}\n    A--&gt;&gt;M: List[Dict]\n    M-&gt;&gt;D: load_dataframe(if_exists='append')\n    D--&gt;&gt;M: rows_loaded\n    M-&gt;&gt;D: update_sync_metadata()</code></pre>"},{"location":"architecture/#base-de-donnees","title":"Base de donn\u00e9es","text":""},{"location":"architecture/#schema-postgresql","title":"Sch\u00e9ma PostgreSQL","text":"<pre><code>-- Sch\u00e9ma principal\nCREATE SCHEMA pennylane;\n\n-- Tables de donn\u00e9es (cr\u00e9\u00e9es dynamiquement)\nCREATE TABLE pennylane.invoices (\n    id SERIAL PRIMARY KEY,\n    -- colonnes dynamiques selon API\n    _loaded_at TIMESTAMP DEFAULT NOW()\n);\n\n-- Logs ETL\nCREATE TABLE pennylane.etl_logs (\n    id SERIAL PRIMARY KEY,\n    execution_date TIMESTAMP DEFAULT NOW(),\n    table_name VARCHAR(255),\n    records_extracted INTEGER,\n    records_loaded INTEGER,\n    status VARCHAR(50),\n    error_message TEXT,\n    execution_time_seconds NUMERIC(10, 2)\n);\n\n-- M\u00e9tadonn\u00e9es synchro\nCREATE TABLE pennylane.sync_metadata (\n    table_name VARCHAR(255) PRIMARY KEY,\n    last_sync_date TIMESTAMP,\n    total_records INTEGER\n);\n</code></pre>"},{"location":"architecture/#optimisations","title":"Optimisations","text":"<p>Batch insert: 1000 lignes par batch Index: Sur colonnes date pour requ\u00eates incr\u00e9mentales Connexion pooling: Context manager Transactions: Commit par batch</p>"},{"location":"architecture/#gestion-configuration","title":"Gestion configuration","text":""},{"location":"architecture/#hierarchie","title":"Hi\u00e9rarchie","text":"<pre><code>1. .env (secrets)\n   \u2193\n2. config_loader.py (validation)\n   \u2193\n3. config.json (endpoints)\n   \u2193\n4. Configuration compl\u00e8te\n</code></pre>"},{"location":"architecture/#securite","title":"S\u00e9curit\u00e9","text":"<ul> <li><code>.env</code> jamais committ\u00e9 (<code>.gitignore</code>)</li> <li>Validation \u00e0 l'initialisation</li> <li>Erreurs explicites si config invalide</li> </ul>"},{"location":"architecture/#rate-limiting","title":"Rate Limiting","text":""},{"location":"architecture/#strategie","title":"Strat\u00e9gie","text":"<pre><code>min_interval = 1.0 / rate_limit  # 4.5 req/s \u2192 0.22s\ntime_since_last = now() - last_request_time\n\nif time_since_last &lt; min_interval:\n    sleep(min_interval - time_since_last)\n</code></pre>"},{"location":"architecture/#gestion-429-rate-limit-exceeded","title":"Gestion 429 (Rate Limit Exceeded)","text":"<pre><code>if response.status_code == 429:\n    retry_after = int(response.headers.get('Retry-After', 60))\n    sleep(retry_after)\n    retry()\n</code></pre>"},{"location":"architecture/#gestion-erreurs","title":"Gestion erreurs","text":""},{"location":"architecture/#niveaux","title":"Niveaux","text":"<ol> <li>Erreur fatale \u2192 Stop imm\u00e9diat (ex: config invalide)</li> <li>Erreur endpoint \u2192 Log + Continue autres endpoints</li> <li>Erreur r\u00e9seau \u2192 Retry avec backoff</li> </ol>"},{"location":"architecture/#logs","title":"Logs","text":"<pre><code># Logs application\nlogs/pennylane_etl.log\n\n# Logs PostgreSQL\npennylane.etl_logs\n</code></pre>"},{"location":"architecture/#performance","title":"Performance","text":""},{"location":"architecture/#optimisations-implementees","title":"Optimisations impl\u00e9ment\u00e9es","text":"<ul> <li>\u2705 Batch insert (1000 rows)</li> <li>\u2705 Pagination automatique</li> <li>\u2705 Rate limiting intelligent</li> <li>\u2705 Context manager DB</li> <li>\u2705 Extraction incr\u00e9mentielle</li> </ul>"},{"location":"architecture/#mesures","title":"Mesures","text":"Volume Temps extraction Temps chargement 10k lignes ~30s ~5s 100k lignes ~5 min ~30s 1M lignes ~45 min ~5 min"},{"location":"architecture/#scalabilite","title":"Scalabilit\u00e9","text":""},{"location":"architecture/#vertical-actuel","title":"Vertical (actuel)","text":"<ul> <li>Single process</li> <li>Sequential endpoints</li> <li>Fonctionne jusqu'\u00e0 1-2M lignes/endpoint</li> </ul>"},{"location":"architecture/#horizontal-futur-v11","title":"Horizontal (futur v1.1)","text":"<ul> <li>Multiprocessing par endpoint</li> <li>Queue syst\u00e8me (Celery/RabbitMQ)</li> <li>Cache Redis</li> </ul>"},{"location":"architecture/#docker","title":"Docker","text":""},{"location":"architecture/#services","title":"Services","text":"<pre><code>postgres:\n  - PostgreSQL 16 Alpine\n  - Optimis\u00e9 analytique\n  - Volumes persistants\n\npgadmin:\n  - Interface web admin\n  - Optionnel\n</code></pre>"},{"location":"architecture/#reseau","title":"R\u00e9seau","text":"<pre><code>Host:5432 \u2190\u2192 Docker:5432 (postgres)\nHost:5050 \u2190\u2192 Docker:80 (pgadmin)\n</code></pre>"},{"location":"architecture/#monitoring","title":"Monitoring","text":""},{"location":"architecture/#metriques-disponibles","title":"M\u00e9triques disponibles","text":"<pre><code>-- Logs ex\u00e9cution\nSELECT table_name,\n       AVG(execution_time_seconds) as avg_time,\n       COUNT(*) as executions,\n       SUM(CASE WHEN status='failed' THEN 1 ELSE 0 END) as failures\nFROM pennylane.etl_logs\nGROUP BY table_name;\n\n-- Derni\u00e8res synchros\nSELECT * FROM pennylane.sync_metadata;\n</code></pre>"},{"location":"architecture/#futur-v13","title":"Futur (v1.3)","text":"<ul> <li>Dashboard Streamlit</li> <li>Alertes email</li> <li>M\u00e9triques temps r\u00e9el</li> </ul>"},{"location":"configuration/","title":"Configuration","text":""},{"location":"configuration/#variables-denvironnement-env","title":"Variables d'environnement (.env)","text":"<p>Toutes les configurations sensibles sont stock\u00e9es dans le fichier <code>.env</code>.</p>"},{"location":"configuration/#variables-obligatoires","title":"Variables obligatoires","text":"Variable Description Exemple <code>PENNYLANE_API_KEY</code> Cl\u00e9 API Pennylane <code>pl_live_abc123...</code> <code>POSTGRES_PASSWORD</code> Mot de passe PostgreSQL <code>MonMotDePasse2025!</code>"},{"location":"configuration/#variables-optionnelles","title":"Variables optionnelles","text":""},{"location":"configuration/#api-pennylane","title":"API Pennylane","text":"<pre><code>PENNYLANE_BASE_URL=https://app.pennylane.com/api/external/v1\nPENNYLANE_RATE_LIMIT=4.5\n</code></pre>"},{"location":"configuration/#postgresql","title":"PostgreSQL","text":"<pre><code>POSTGRES_HOST=localhost\nPOSTGRES_PORT=5432\nPOSTGRES_DB=pennylane_data\nPOSTGRES_USER=pennylane_user\nPOSTGRES_SCHEMA=pennylane\n</code></pre>"},{"location":"configuration/#planificateur","title":"Planificateur","text":"<pre><code>SCHEDULER_INTERVAL_MINUTES=10\nSCHEDULER_ENABLED=true\n</code></pre>"},{"location":"configuration/#logging","title":"Logging","text":"<pre><code>LOG_LEVEL=INFO\nLOG_FILE=logs/pennylane_etl.log\nLOG_MAX_BYTES=10485760\nLOG_BACKUP_COUNT=5\n</code></pre>"},{"location":"configuration/#configuration-des-endpoints-configjson","title":"Configuration des endpoints (config.json)","text":"<p>Le fichier <code>config.json</code> d\u00e9finit quels endpoints Pennylane synchroniser.</p>"},{"location":"configuration/#structure","title":"Structure","text":"<pre><code>{\n  \"endpoints\": {\n    \"enabled\": [\n      {\n        \"name\": \"invoices\",\n        \"endpoint\": \"/customer_invoices\",\n        \"table_name\": \"invoices\",\n        \"incremental\": true,\n        \"date_field\": \"updated_at\"\n      }\n    ]\n  }\n}\n</code></pre>"},{"location":"configuration/#parametres","title":"Param\u00e8tres","text":"<ul> <li>name : Nom descriptif</li> <li>endpoint : Chemin API Pennylane</li> <li>table_name : Nom table PostgreSQL</li> <li>incremental : Extraction incr\u00e9mentielle (true/false)</li> <li>date_field : Champ date pour filtre incr\u00e9mentiel</li> </ul>"},{"location":"configuration/#endpoints-disponibles","title":"Endpoints disponibles","text":"Endpoint Description Incr\u00e9mentiel <code>/customer_invoices</code> Factures clients \u2705 <code>/supplier_invoices</code> Factures fournisseurs \u2705 <code>/customers</code> Clients \u2705 <code>/suppliers</code> Fournisseurs \u2705 <code>/transactions</code> Transactions bancaires \u2705 <code>/journal_entries</code> \u00c9critures comptables \u2705 <code>/plan_items</code> Plan comptable \u274c <code>/categories</code> Cat\u00e9gories analytiques \u274c <code>/payment_methods</code> Moyens de paiement \u274c"},{"location":"configuration/#ajouter-un-endpoint","title":"Ajouter un endpoint","text":"<pre><code>{\n  \"name\": \"products\",\n  \"endpoint\": \"/products\",\n  \"table_name\": \"products\",\n  \"incremental\": true,\n  \"date_field\": \"updated_at\"\n}\n</code></pre>"},{"location":"configuration/#configuration-docker","title":"Configuration Docker","text":"<p>Le fichier <code>docker-compose.yml</code> utilise les variables <code>.env</code>.</p>"},{"location":"configuration/#ports-par-defaut","title":"Ports par d\u00e9faut","text":"<ul> <li>PostgreSQL : <code>5432</code></li> <li>pgAdmin : <code>5050</code></li> </ul>"},{"location":"configuration/#changer-les-ports","title":"Changer les ports","text":"<p>Dans <code>.env</code> :</p> <pre><code>POSTGRES_PORT=5433\nPGADMIN_PORT=5051\n</code></pre>"},{"location":"configuration/#securite","title":"S\u00e9curit\u00e9","text":"<p>Ne JAMAIS commiter .env</p> <p>Le fichier <code>.env</code> contient vos secrets et est ignor\u00e9 par Git.</p> <p>Bonnes pratiques</p> <ul> <li>Mot de passe PostgreSQL : 16+ caract\u00e8res, majuscules, minuscules, chiffres, symboles</li> <li>Cl\u00e9 API : Ne jamais partager, r\u00e9g\u00e9n\u00e9rer si compromise</li> <li>Sauvegarder <code>.env</code> de fa\u00e7on s\u00e9curis\u00e9e (gestionnaire mots de passe)</li> </ul>"},{"location":"depannage/","title":"D\u00e9pannage","text":"<p>Guide de r\u00e9solution des probl\u00e8mes courants.</p>"},{"location":"depannage/#erreurs-de-configuration","title":"Erreurs de configuration","text":""},{"location":"depannage/#variable-denvironnement-pennylane_api_key-requise","title":"\"Variable d'environnement PENNYLANE_API_KEY requise\"","text":"<p>Cause: Fichier <code>.env</code> absent ou mal configur\u00e9</p> <p>Solution:</p> <pre><code># 1. V\u00e9rifier que .env existe\nls -la .env  # Linux/Mac\ndir .env     # Windows\n\n# 2. Si absent, cr\u00e9er depuis template\ncp .env.example .env\n\n# 3. \u00c9diter et configurer\nnano .env\n</code></pre>"},{"location":"depannage/#cle-api-pennylane-invalide","title":"\"Cl\u00e9 API Pennylane invalide\"","text":"<p>Cause: API key incorrecte ou contenant des espaces</p> <p>Solution:</p> <pre><code># V\u00e9rifier format dans .env (pas d'espaces)\nPENNYLANE_API_KEY=pl_live_abc123...\n</code></pre> <p>Obtenir nouvelle cl\u00e9</p> <p>app.pennylane.com \u2192 Param\u00e8tres \u2192 API</p>"},{"location":"depannage/#erreurs-postgresql","title":"Erreurs PostgreSQL","text":""},{"location":"depannage/#erreur-connexion-postgresql","title":"\"Erreur connexion PostgreSQL\"","text":"<p>Cause: Docker pas d\u00e9marr\u00e9 ou conteneur arr\u00eat\u00e9</p> <p>Solution:</p> <pre><code># 1. V\u00e9rifier Docker Desktop\ndocker --version\n\n# 2. V\u00e9rifier conteneurs\ndocker ps\n\n# 3. Red\u00e9marrer si n\u00e9cessaire\ndocker-compose restart postgres\n\n# 4. Logs PostgreSQL\ndocker logs pennylane_postgres\n</code></pre>"},{"location":"depannage/#mot-de-passe-postgresql-invalide","title":"\"Mot de passe PostgreSQL invalide\"","text":"<p>Cause: Password dans <code>.env</code> diff\u00e9rent de celui configur\u00e9</p> <p>Solution:</p> <pre><code># 1. Arr\u00eater et supprimer volumes\ndocker-compose down -v\n\n# 2. Configurer nouveau password dans .env\nnano .env\n\n# 3. Red\u00e9marrer\ndocker-compose up -d\n</code></pre>"},{"location":"depannage/#table-introuvable","title":"\"Table introuvable\"","text":"<p>Cause: Base non initialis\u00e9e ou extraction pas lanc\u00e9e</p> <p>Solution:</p> <pre><code># Lancer premi\u00e8re extraction\ncd src\npython main.py full\n</code></pre>"},{"location":"depannage/#erreurs-api-pennylane","title":"Erreurs API Pennylane","text":""},{"location":"depannage/#rate-limit-depasse-429","title":"\"Rate limit d\u00e9pass\u00e9 (429)\"","text":"<p>Cause: Trop de requ\u00eates en peu de temps</p> <p>Solution: Le script g\u00e8re automatiquement, mais si persistant :</p> <pre><code># R\u00e9duire dans .env\nPENNYLANE_RATE_LIMIT=3.0\n</code></pre>"},{"location":"depannage/#endpoint-non-trouve-404","title":"\"Endpoint non trouv\u00e9 (404)\"","text":"<p>Cause: Endpoint incorrect dans <code>config.json</code></p> <p>Solution:</p> <p>V\u00e9rifier dans documentation API Pennylane</p>"},{"location":"depannage/#timeout-api","title":"\"Timeout API\"","text":"<p>Cause: Connexion lente ou API indisponible</p> <p>Solution:</p> <pre><code># V\u00e9rifier connexion internet\nping app.pennylane.com\n\n# V\u00e9rifier status API\ncurl https://status.pennylane.com\n</code></pre>"},{"location":"depannage/#erreurs-dextraction","title":"Erreurs d'extraction","text":""},{"location":"depannage/#aucune-donnee-extraite","title":"\"Aucune donn\u00e9e extraite\"","text":"<p>Cause: Filtre incr\u00e9mentiel trop restrictif ou pas de nouvelles donn\u00e9es</p> <p>Solution:</p> <pre><code># Forcer extraction compl\u00e8te\npython main.py full\n</code></pre>"},{"location":"depannage/#extraction-tres-lente","title":"\"Extraction tr\u00e8s lente\"","text":"<p>Cause: Gros volume ou rate limiting</p> <p>Solution:</p> <ul> <li>Patience (normal pour premi\u00e8re extraction)</li> <li>V\u00e9rifier logs : <code>tail -f logs/pennylane_etl.log</code></li> <li>Limiter endpoints dans <code>config.json</code></li> </ul>"},{"location":"depannage/#erreurs-python","title":"Erreurs Python","text":""},{"location":"depannage/#modulenotfounderror","title":"\"ModuleNotFoundError\"","text":"<p>Cause: D\u00e9pendances non install\u00e9es</p> <p>Solution:</p> <pre><code>pip install -r requirements.txt --upgrade\n</code></pre>"},{"location":"depannage/#importerror-config_loader","title":"\"ImportError: config_loader\"","text":"<p>Cause: Pas dans bon r\u00e9pertoire</p> <p>Solution:</p> <pre><code># Toujours lancer depuis src/\ncd src\npython main.py full\n</code></pre>"},{"location":"depannage/#problemes-docker","title":"Probl\u00e8mes Docker","text":""},{"location":"depannage/#cannot-connect-to-docker-daemon","title":"\"Cannot connect to Docker daemon\"","text":"<p>Cause: Docker Desktop pas d\u00e9marr\u00e9</p> <p>Solution:</p> <ol> <li>D\u00e9marrer Docker Desktop</li> <li>Attendre initialisation compl\u00e8te</li> <li>Relancer <code>docker-compose up -d</code></li> </ol>"},{"location":"depannage/#port-5432-deja-utilise","title":"\"Port 5432 d\u00e9j\u00e0 utilis\u00e9\"","text":"<p>Cause: Autre PostgreSQL actif</p> <p>Solution:</p> <pre><code># Option 1: Arr\u00eater autre PostgreSQL\n# Option 2: Changer port dans .env\nPOSTGRES_PORT=5433\n</code></pre>"},{"location":"depannage/#port-5050-deja-utilise","title":"\"Port 5050 d\u00e9j\u00e0 utilis\u00e9\"","text":"<p>Solution:</p> <pre><code># Changer port pgAdmin\nPGADMIN_PORT=5051\n</code></pre>"},{"location":"depannage/#logs-et-diagnostics","title":"Logs et diagnostics","text":""},{"location":"depannage/#consulter-tous-les-logs","title":"Consulter tous les logs","text":"<pre><code># Logs application\ncat logs/pennylane_etl.log\n\n# Logs PostgreSQL\ndocker logs pennylane_postgres\n\n# Logs pgAdmin\ndocker logs pennylane_pgadmin\n</code></pre>"},{"location":"depannage/#niveau-debug","title":"Niveau DEBUG","text":"<p>Pour diagnostics d\u00e9taill\u00e9s :</p> <pre><code># Dans .env\nLOG_LEVEL=DEBUG\n</code></pre>"},{"location":"depannage/#verifier-tables-creees","title":"V\u00e9rifier tables cr\u00e9\u00e9es","text":"<pre><code>SELECT table_name,\n       (SELECT COUNT(*) FROM pennylane.table_name) as row_count\nFROM information_schema.tables\nWHERE table_schema = 'pennylane';\n</code></pre>"},{"location":"depannage/#verifier-logs-etl","title":"V\u00e9rifier logs ETL","text":"<pre><code>SELECT *\nFROM pennylane.etl_logs\nWHERE status = 'failed'\nORDER BY execution_date DESC\nLIMIT 10;\n</code></pre>"},{"location":"depannage/#reinitialisation-complete","title":"R\u00e9initialisation compl\u00e8te","text":"<p>Si rien ne fonctionne, r\u00e9initialisation totale :</p> <pre><code># 1. Arr\u00eater tout\ndocker-compose down -v\n\n# 2. Supprimer logs\nrm -rf logs/*\n\n# 3. V\u00e9rifier .env\ncat .env\n\n# 4. R\u00e9installer d\u00e9pendances\npip install -r requirements.txt --force-reinstall\n\n# 5. Red\u00e9marrer\ndocker-compose up -d\nsleep 10\ncd src &amp;&amp; python main.py full\n</code></pre>"},{"location":"depannage/#support","title":"Support","text":"<p>Si probl\u00e8me persiste :</p> <ol> <li>V\u00e9rifier issues GitHub : github.com/yves34690/Penny/issues</li> <li>Cr\u00e9er nouvelle issue avec :</li> <li>Message d'erreur complet</li> <li>Logs pertinents</li> <li>\u00c9tapes pour reproduire</li> <li>Documentation Pennylane : pennylane.readme.io</li> </ol>"},{"location":"faq/","title":"FAQ (Questions fr\u00e9quentes)","text":""},{"location":"faq/#questions-generales","title":"Questions g\u00e9n\u00e9rales","text":""},{"location":"faq/#penny-est-il-gratuit","title":"Penny est-il gratuit ?","text":"<p>Oui, Penny est open-source sous licence MIT. Gratuit pour usage personnel et commercial.</p>"},{"location":"faq/#quels-sont-les-prerequis","title":"Quels sont les pr\u00e9requis ?","text":"<ul> <li>Compte Pennylane Premium + Module comptable</li> <li>Python 3.12+</li> <li>Docker Desktop</li> <li>Cl\u00e9 API Pennylane</li> </ul>"},{"location":"faq/#fonctionne-t-il-sur-maclinux","title":"Fonctionne-t-il sur Mac/Linux ?","text":"<p>Oui, compatible Windows, macOS et Linux.</p>"},{"location":"faq/#installation","title":"Installation","text":""},{"location":"faq/#linstallation-prend-combien-de-temps","title":"L'installation prend combien de temps ?","text":"<p>Environ 10 minutes pour installation compl\u00e8te : - 2 min : Clone + d\u00e9pendances Python - 3 min : Configuration .env - 5 min : Docker + premi\u00e8re extraction</p>"},{"location":"faq/#puis-je-utiliser-sans-docker","title":"Puis-je utiliser sans Docker ?","text":"<p>Non recommand\u00e9. PostgreSQL via Docker simplifie installation et garantit compatibilit\u00e9.</p> <p>Alternative : Installer PostgreSQL nativement et adapter <code>config.json</code>.</p>"},{"location":"faq/#configuration","title":"Configuration","text":""},{"location":"faq/#comment-obtenir-ma-cle-api-pennylane","title":"Comment obtenir ma cl\u00e9 API Pennylane ?","text":"<ol> <li>app.pennylane.com</li> <li>Param\u00e8tres \u2192 API</li> <li>G\u00e9n\u00e9rer une cl\u00e9 API</li> <li>Copier dans <code>.env</code></li> </ol>"},{"location":"faq/#puis-je-utiliser-plusieurs-cles-api","title":"Puis-je utiliser plusieurs cl\u00e9s API ?","text":"<p>Oui, pour multi-comptes :</p> <pre><code># .env pour client A\nPENNYLANE_API_KEY=cle_client_a\nPOSTGRES_DB=client_a_data\n</code></pre> <p>Dupliquer projet ou changer <code>.env</code> entre ex\u00e9cutions.</p>"},{"location":"faq/#comment-changer-lintervalle-dactualisation","title":"Comment changer l'intervalle d'actualisation ?","text":"<pre><code># .env - Actualisation toutes les 5 minutes\nSCHEDULER_INTERVAL_MINUTES=5\n</code></pre>"},{"location":"faq/#utilisation","title":"Utilisation","text":""},{"location":"faq/#dois-je-laisser-le-planificateur-tourner-en-continu","title":"Dois-je laisser le planificateur tourner en continu ?","text":"<p>Recommand\u00e9 : Oui, pour actualisation temps r\u00e9el.</p> <p>Alternative : Ex\u00e9cution manuelle ou via cron/Task Scheduler.</p>"},{"location":"faq/#puis-je-arreter-pendant-une-extraction","title":"Puis-je arr\u00eater pendant une extraction ?","text":"<p>Oui (<code>Ctrl+C</code>). L'extraction sera reprise \u00e0 la prochaine ex\u00e9cution (mode incr\u00e9mentiel).</p>"},{"location":"faq/#que-se-passe-t-il-si-mon-pc-seteint","title":"Que se passe-t-il si mon PC s'\u00e9teint ?","text":"<p>Aucun probl\u00e8me. Donn\u00e9es PostgreSQL sauvegard\u00e9es. Relancer apr\u00e8s red\u00e9marrage.</p>"},{"location":"faq/#comment-savoir-si-lextraction-fonctionne","title":"Comment savoir si l'extraction fonctionne ?","text":"<pre><code># Logs temps r\u00e9el\ntail -f logs/pennylane_etl.log\n\n# Logs PostgreSQL\nSELECT * FROM pennylane.etl_logs\nORDER BY execution_date DESC LIMIT 10;\n</code></pre>"},{"location":"faq/#performance","title":"Performance","text":""},{"location":"faq/#combien-de-temps-pour-premiere-extraction","title":"Combien de temps pour premi\u00e8re extraction ?","text":"<p>D\u00e9pend du volume : - &lt; 10k lignes : 1-2 min - 100k lignes : 5-10 min - 1M lignes : 30-60 min</p>"},{"location":"faq/#lactualisation-incrementielle-est-plus-rapide","title":"L'actualisation incr\u00e9mentielle est plus rapide ?","text":"<p>Oui, beaucoup plus rapide : - Compl\u00e8te : 30 min - Incr\u00e9mentielle : 30 sec (si peu de changements)</p>"},{"location":"faq/#mon-power-bi-est-toujours-lent","title":"Mon Power BI est toujours lent","text":"<p>V\u00e9rifiez : 1. Connexion en mode Import (pas DirectQuery) 2. Transformations dans Jupyter (pas Power Query) 3. Tables index\u00e9es dans PostgreSQL</p>"},{"location":"faq/#donnees","title":"Donn\u00e9es","text":""},{"location":"faq/#quels-endpoints-sont-synchronises","title":"Quels endpoints sont synchronis\u00e9s ?","text":"<p>Par d\u00e9faut : - Factures clients/fournisseurs - Clients/Fournisseurs - Transactions bancaires - \u00c9critures comptables - Plan comptable - Cat\u00e9gories</p> <p>Modifiable dans <code>config.json</code>.</p>"},{"location":"faq/#puis-je-synchroniser-seulement-certaines-tables","title":"Puis-je synchroniser seulement certaines tables ?","text":"<p>Oui, \u00e9diter <code>config.json</code> et retirer endpoints non d\u00e9sir\u00e9s.</p>"},{"location":"faq/#les-donnees-sont-elles-historisees","title":"Les donn\u00e9es sont-elles historis\u00e9es ?","text":"<p>Non par d\u00e9faut (derni\u00e8re version uniquement).</p> <p>Pour historisation, impl\u00e9menter : <pre><code>CREATE TABLE pennylane.invoices_history (\n    -- m\u00eame structure + colonne version/date\n);\n</code></pre></p>"},{"location":"faq/#comment-supprimer-toutes-les-donnees","title":"Comment supprimer toutes les donn\u00e9es ?","text":"<pre><code>docker-compose down -v  # -v supprime volumes\ndocker-compose up -d\n</code></pre>"},{"location":"faq/#securite","title":"S\u00e9curit\u00e9","text":""},{"location":"faq/#mes-donnees-sont-elles-securisees","title":"Mes donn\u00e9es sont-elles s\u00e9curis\u00e9es ?","text":"<ul> <li>\u2705 Donn\u00e9es stock\u00e9es localement (votre machine)</li> <li>\u2705 Pas de cloud tiers</li> <li>\u2705 Secrets dans <code>.env</code> (non committ\u00e9)</li> <li>\u2705 PostgreSQL avec mot de passe</li> </ul>"},{"location":"faq/#puis-je-partager-mon-depot","title":"Puis-je partager mon d\u00e9p\u00f4t ?","text":"<p>Oui, mais : - \u274c JAMAIS commiter <code>.env</code> - \u2705 Partager <code>.env.example</code> - \u2705 Chacun configure son <code>.env</code></p>"},{"location":"faq/#le-mot-de-passe-postgresql-est-il-important","title":"Le mot de passe PostgreSQL est-il important ?","text":"<p>Localement : moins critique Serveur : tr\u00e8s important (acc\u00e8s r\u00e9seau)</p>"},{"location":"faq/#power-bi","title":"Power BI","text":""},{"location":"faq/#comment-connecter-power-bi","title":"Comment connecter Power BI ?","text":"<p>Obtenir les donn\u00e9es \u2192 PostgreSQL - Serveur : <code>localhost</code> - Base : <code>pennylane_data</code> - Mode : Import</p>"},{"location":"faq/#directquery-ou-import","title":"DirectQuery ou Import ?","text":"<p>Import recommand\u00e9 pour : - Performance - Gros volumes - Transformations complexes</p>"},{"location":"faq/#actualisation-power-bi","title":"Actualisation Power BI","text":"<ol> <li>Desktop : Bouton Actualiser</li> <li>Service : Planifier actualisation (ex: toutes les heures)</li> </ol> <p>Donn\u00e9es Penny actualis\u00e9es toutes les 10 min \u2192 Power BI toujours quasi \u00e0 jour !</p>"},{"location":"faq/#depannage","title":"D\u00e9pannage","text":""},{"location":"faq/#variable-pennylane_api_key-requise","title":"\"Variable PENNYLANE_API_KEY requise\"","text":"<p>Cr\u00e9er fichier <code>.env</code> depuis <code>.env.example</code> et configurer.</p>"},{"location":"faq/#erreur-connexion-postgresql","title":"\"Erreur connexion PostgreSQL\"","text":"<pre><code>docker ps  # V\u00e9rifier conteneur actif\ndocker-compose restart postgres\n</code></pre>"},{"location":"faq/#aucune-donnee-extraite","title":"\"Aucune donn\u00e9e extraite\"","text":"<pre><code># Forcer extraction compl\u00e8te\npython main.py full\n</code></pre>"},{"location":"faq/#autres-problemes","title":"Autres probl\u00e8mes ?","text":"<p>Voir guide de d\u00e9pannage.</p>"},{"location":"faq/#evolutions","title":"\u00c9volutions","text":""},{"location":"faq/#nouvelles-fonctionnalites-prevues","title":"Nouvelles fonctionnalit\u00e9s pr\u00e9vues ?","text":"<p>Voir roadmap dans guide utilisateur.</p>"},{"location":"faq/#puis-je-contribuer","title":"Puis-je contribuer ?","text":"<p>Oui ! Pull requests bienvenues sur GitHub.</p>"},{"location":"faq/#comment-demander-une-fonctionnalite","title":"Comment demander une fonctionnalit\u00e9 ?","text":"<p>Cr\u00e9er une issue avec label \"enhancement\".</p>"},{"location":"faq/#support","title":"Support","text":""},{"location":"faq/#ou-trouver-de-laide","title":"O\u00f9 trouver de l'aide ?","text":"<ol> <li>Cette documentation</li> <li>Issues GitHub</li> <li>Documentation Pennylane</li> </ol>"},{"location":"faq/#puis-je-contacter-directement","title":"Puis-je contacter directement ?","text":"<p>Via issues GitHub (r\u00e9ponse sous 24-48h).</p>"},{"location":"faq/#licence","title":"Licence","text":""},{"location":"faq/#puis-je-utiliser-commercialement","title":"Puis-je utiliser commercialement ?","text":"<p>Oui, licence MIT = usage libre (personnel et commercial).</p>"},{"location":"faq/#puis-je-revendre-penny","title":"Puis-je revendre Penny ?","text":"<p>Oui, mais : - Mentionner licence MIT - Cr\u00e9diter auteur original - Open-source (pas propri\u00e9taire)</p>"},{"location":"guide-demarrage/","title":"Guide de d\u00e9marrage rapide","text":"<p>Ce guide vous permettra d'installer et configurer Penny en moins de 10 minutes.</p>"},{"location":"guide-demarrage/#prerequis","title":"Pr\u00e9requis","text":"<p>Avant de commencer, assurez-vous d'avoir :</p> <ul> <li>[x] Python 3.12 ou sup\u00e9rieur</li> <li>[x] Docker Desktop install\u00e9 et d\u00e9marr\u00e9</li> <li>[x] Une cl\u00e9 API Pennylane (Premium + Module comptable)</li> <li>[x] Git install\u00e9</li> </ul>"},{"location":"guide-demarrage/#installation","title":"Installation","text":""},{"location":"guide-demarrage/#etape-1-cloner-le-depot","title":"\u00c9tape 1 : Cloner le d\u00e9p\u00f4t","text":"<pre><code>git clone https://github.com/yves34690/Penny.git\ncd Penny\n</code></pre>"},{"location":"guide-demarrage/#etape-2-configurer-les-secrets","title":"\u00c9tape 2 : Configurer les secrets","text":"<pre><code># Copier le template\ncp .env.example .env\n\n# \u00c9diter avec vos valeurs\nnotepad .env  # Windows\nnano .env     # Linux/Mac\n</code></pre> <p>Variables obligatoires</p> <p>Vous DEVEZ configurer au minimum :</p> <ul> <li><code>PENNYLANE_API_KEY</code> : Votre cl\u00e9 API Pennylane</li> <li><code>POSTGRES_PASSWORD</code> : Un mot de passe s\u00e9curis\u00e9</li> </ul>"},{"location":"guide-demarrage/#etape-3-installer-les-dependances","title":"\u00c9tape 3 : Installer les d\u00e9pendances","text":"<pre><code>pip install -r requirements.txt\n</code></pre>"},{"location":"guide-demarrage/#etape-4-demarrer-postgresql","title":"\u00c9tape 4 : D\u00e9marrer PostgreSQL","text":"<pre><code>docker-compose up -d\n</code></pre> <p>V\u00e9rifiez que tout fonctionne :</p> <pre><code>docker ps\n</code></pre> <p>Vous devriez voir 2 conteneurs actifs : - <code>pennylane_postgres</code> - <code>pennylane_pgadmin</code></p>"},{"location":"guide-demarrage/#etape-5-premiere-extraction","title":"\u00c9tape 5 : Premi\u00e8re extraction","text":"<pre><code>cd src\npython main.py full\n</code></pre> <p>Succ\u00e8s !</p> <p>Si vous voyez <code>\u2713 Configuration charg\u00e9e et valid\u00e9e</code>, tout fonctionne !</p>"},{"location":"guide-demarrage/#verification","title":"V\u00e9rification","text":""},{"location":"guide-demarrage/#acceder-a-pgadmin","title":"Acc\u00e9der \u00e0 pgAdmin","text":"<p>Ouvrez http://localhost:5050</p> <ul> <li>Email : <code>admin@pennylane.local</code></li> <li>Password : <code>admin</code></li> </ul>"},{"location":"guide-demarrage/#consulter-les-donnees","title":"Consulter les donn\u00e9es","text":"<pre><code>SELECT table_name\nFROM information_schema.tables\nWHERE table_schema = 'pennylane';\n</code></pre>"},{"location":"guide-demarrage/#prochaines-etapes","title":"Prochaines \u00e9tapes","text":"<ul> <li>Guide utilisateur complet</li> <li>Configuration avanc\u00e9e</li> <li>Connexion Power BI</li> </ul>"},{"location":"guide-utilisateur/","title":"\ud83d\udcd6 Guide Utilisateur - ETL Pennylane","text":"<p>Version : 1.0 Derni\u00e8re mise \u00e0 jour : 2025-10-07 Auteur : yves34690</p>"},{"location":"guide-utilisateur/#table-des-matieres","title":"\ud83d\udccb Table des mati\u00e8res","text":"<ol> <li>Introduction</li> <li>Pr\u00e9requis</li> <li>Installation</li> <li>Configuration</li> <li>Utilisation quotidienne</li> <li>Maintenance</li> <li>D\u00e9pannage</li> <li>\u00c9volutions futures</li> </ol>"},{"location":"guide-utilisateur/#introduction","title":"\ud83c\udfaf Introduction","text":""},{"location":"guide-utilisateur/#quest-ce-que-penny","title":"Qu'est-ce que Penny ?","text":"<p>Penny est une solution ETL (Extract, Transform, Load) qui : - Extrait les donn\u00e9es de l'API Pennylane toutes les 10 minutes - Les stocke dans une base PostgreSQL - Permet une connexion rapide \u00e0 Power BI pour analyse</p>"},{"location":"guide-utilisateur/#problemes-resolus","title":"Probl\u00e8mes r\u00e9solus","text":"Probl\u00e8me Avant Avec Penny Actualisation API Pennylane 2 heures 10 minutes Actualisation Power BI 30-60 min (lent) 2-5 min (rapide) Transformations donn\u00e9es Power Query Python + SQL Volume support\u00e9 Limit\u00e9 Millions de lignes"},{"location":"guide-utilisateur/#architecture-globale","title":"Architecture globale","text":"<pre><code>Pennylane API \u2192 Python ETL (10 min) \u2192 PostgreSQL \u2192 Jupyter/Power BI\n</code></pre>"},{"location":"guide-utilisateur/#prerequis","title":"\ud83d\udd27 Pr\u00e9requis","text":""},{"location":"guide-utilisateur/#logiciels-necessaires","title":"Logiciels n\u00e9cessaires","text":"<ul> <li>[x] Python 3.12+ (t\u00e9l\u00e9charger)</li> <li>[x] Docker Desktop (t\u00e9l\u00e9charger)</li> <li>[x] Git (t\u00e9l\u00e9charger)</li> <li>[x] \u00c9diteur de texte (VS Code recommand\u00e9)</li> </ul>"},{"location":"guide-utilisateur/#comptes-et-acces","title":"Comptes et acc\u00e8s","text":"<ul> <li>[x] Compte Pennylane avec offre Premium + Module comptable</li> <li>[x] Cl\u00e9 API Pennylane (voir obtenir cl\u00e9 API)</li> <li>[x] Power BI Desktop (optionnel, pour visualisation)</li> </ul>"},{"location":"guide-utilisateur/#installation","title":"\ud83d\udce5 Installation","text":""},{"location":"guide-utilisateur/#etape-1-cloner-le-depot","title":"\u00c9tape 1 : Cloner le d\u00e9p\u00f4t","text":"<pre><code># Via HTTPS\ngit clone https://github.com/yves34690/Penny.git\ncd Penny\n\n# Via SSH (si configur\u00e9)\ngit clone git@github.com:yves34690/Penny.git\ncd Penny\n</code></pre>"},{"location":"guide-utilisateur/#etape-2-creer-fichier-env","title":"\u00c9tape 2 : Cr\u00e9er fichier .env","text":"<pre><code># Windows\ncopy .env.example .env\nnotepad .env\n\n# Linux/Mac\ncp .env.example .env\nnano .env\n</code></pre> <p>\u26a0\ufe0f IMPORTANT : Configurer au minimum ces 2 variables dans <code>.env</code> :</p> <pre><code>PENNYLANE_API_KEY=votre_cle_api_ici\nPOSTGRES_PASSWORD=votre_mot_de_passe_securise\n</code></pre>"},{"location":"guide-utilisateur/#etape-3-installer-dependances-python","title":"\u00c9tape 3 : Installer d\u00e9pendances Python","text":"<pre><code>pip install -r requirements.txt\n</code></pre>"},{"location":"guide-utilisateur/#etape-4-demarrer-postgresql","title":"\u00c9tape 4 : D\u00e9marrer PostgreSQL","text":"<pre><code>docker-compose up -d\n</code></pre> <p>V\u00e9rification :</p> <pre><code>docker ps\n# Vous devriez voir : pennylane_postgres et pennylane_pgadmin\n</code></pre>"},{"location":"guide-utilisateur/#etape-5-premier-test","title":"\u00c9tape 5 : Premier test","text":"<pre><code>cd src\npython main.py full\n</code></pre> <p>Si tout fonctionne, vous verrez : <pre><code>================================================================================\nETL Pennylane \u2192 PostgreSQL\nMode: FULL\n...\n\u2713 Configuration charg\u00e9e et valid\u00e9e\n\u2713 Connexion r\u00e9ussie\n...\n</code></pre></p>"},{"location":"guide-utilisateur/#configuration","title":"\u2699\ufe0f Configuration","text":""},{"location":"guide-utilisateur/#obtenir-cle-api-pennylane","title":"Obtenir cl\u00e9 API Pennylane","text":"<ol> <li>Connexion sur app.pennylane.com</li> <li>Param\u00e8tres \u2192 API</li> <li>Cliquer sur G\u00e9n\u00e9rer une cl\u00e9 API</li> <li>Copier la cl\u00e9</li> <li>Coller dans <code>.env</code> : <code>PENNYLANE_API_KEY=votre_cle</code></li> </ol>"},{"location":"guide-utilisateur/#personnaliser-les-endpoints","title":"Personnaliser les endpoints","text":"<p>\u00c9diter config.json pour activer/d\u00e9sactiver endpoints :</p> <pre><code>{\n  \"endpoints\": {\n    \"enabled\": [\n      {\n        \"name\": \"invoices\",\n        \"endpoint\": \"/customer_invoices\",\n        \"table_name\": \"invoices\",\n        \"incremental\": true,\n        \"date_field\": \"updated_at\"\n      }\n      // Ajouter/retirer des endpoints ici\n    ]\n  }\n}\n</code></pre>"},{"location":"guide-utilisateur/#changer-lintervalle-dactualisation","title":"Changer l'intervalle d'actualisation","text":"<p>Dans <code>.env</code> :</p> <pre><code>SCHEDULER_INTERVAL_MINUTES=5  # Au lieu de 10\n</code></pre>"},{"location":"guide-utilisateur/#utilisation-quotidienne","title":"\ud83d\ude80 Utilisation quotidienne","text":""},{"location":"guide-utilisateur/#mode-manuel-extraction-ponctuelle","title":"Mode manuel (extraction ponctuelle)","text":""},{"location":"guide-utilisateur/#extraction-complete-toutes-les-donnees","title":"Extraction compl\u00e8te (toutes les donn\u00e9es)","text":"<pre><code>cd src\npython main.py full\n</code></pre> <p>Quand utiliser : - Premi\u00e8re installation - Apr\u00e8s modification des endpoints - R\u00e9initialisation compl\u00e8te</p>"},{"location":"guide-utilisateur/#extraction-incrementielle-nouveaux-enregistrements","title":"Extraction incr\u00e9mentielle (nouveaux enregistrements)","text":"<pre><code>cd src\npython main.py incremental\n</code></pre> <p>Quand utiliser : - Actualisation manuelle rapide - Test apr\u00e8s modification code - R\u00e9cup\u00e9ration apr\u00e8s erreur</p>"},{"location":"guide-utilisateur/#mode-automatique-planificateur","title":"Mode automatique (planificateur)","text":"<pre><code>cd src\npython scheduler.py\n</code></pre> <p>Fonctionnement : - Ex\u00e9cution automatique toutes les 10 minutes (configurable) - Mode incr\u00e9mentiel (rapide) - Tourne en continu jusqu'\u00e0 <code>Ctrl+C</code></p> <p>Logs en temps r\u00e9el :</p> <pre><code># Dans un autre terminal\ntype logs\\pennylane_etl.log  # Windows\ntail -f logs/pennylane_etl.log  # Linux/Mac\n</code></pre>"},{"location":"guide-utilisateur/#acceder-aux-donnees","title":"Acc\u00e9der aux donn\u00e9es","text":""},{"location":"guide-utilisateur/#via-pgadmin-interface-web","title":"Via pgAdmin (interface web)","text":"<p>http://localhost:5050</p> <ul> <li>Email : <code>admin@pennylane.local</code></li> <li>Password : <code>admin</code></li> </ul> <p>Ajouter serveur : - Host : <code>postgres</code> - Port : <code>5432</code> - Database : <code>pennylane_data</code> - Username : <code>pennylane_user</code> - Password : (voir <code>.env</code>)</p>"},{"location":"guide-utilisateur/#via-jupyter-notebook","title":"Via Jupyter Notebook","text":"<pre><code>import pandas as pd\nfrom sqlalchemy import create_engine\nfrom dotenv import load_dotenv\nimport os\n\nload_dotenv()\n\n# Connexion\nengine = create_engine(\n    f\"postgresql://{os.getenv('POSTGRES_USER')}:{os.getenv('POSTGRES_PASSWORD')}\"\n    f\"@{os.getenv('POSTGRES_HOST')}:{os.getenv('POSTGRES_PORT')}/{os.getenv('POSTGRES_DB')}\"\n)\n\n# Charger table\ndf = pd.read_sql('SELECT * FROM pennylane.invoices', engine)\nprint(f\"{len(df)} factures charg\u00e9es\")\n</code></pre>"},{"location":"guide-utilisateur/#via-power-bi","title":"Via Power BI","text":"<ol> <li>Obtenir les donn\u00e9es \u2192 PostgreSQL</li> <li>Serveur : <code>localhost</code>, Base : <code>pennylane_data</code></li> <li>Sch\u00e9ma : <code>pennylane</code></li> <li>S\u00e9lectionner tables n\u00e9cessaires</li> <li>Importer (pas DirectQuery)</li> </ol>"},{"location":"guide-utilisateur/#maintenance","title":"\ud83d\udd04 Maintenance","text":""},{"location":"guide-utilisateur/#logs-et-monitoring","title":"Logs et monitoring","text":""},{"location":"guide-utilisateur/#consulter-logs-dexecution","title":"Consulter logs d'ex\u00e9cution","text":"<pre><code># Derni\u00e8res lignes\ntype logs\\pennylane_etl.log  # Windows\ntail logs/pennylane_etl.log  # Linux/Mac\n\n# Suivi temps r\u00e9el\ntail -f logs/pennylane_etl.log  # Linux/Mac\nGet-Content logs\\pennylane_etl.log -Wait  # PowerShell\n</code></pre>"},{"location":"guide-utilisateur/#verifier-logs-etl-dans-postgresql","title":"V\u00e9rifier logs ETL dans PostgreSQL","text":"<pre><code>SELECT * FROM pennylane.etl_logs\nWHERE status = 'failed'\nORDER BY execution_date DESC;\n</code></pre>"},{"location":"guide-utilisateur/#sauvegardes","title":"Sauvegardes","text":""},{"location":"guide-utilisateur/#sauvegarder-postgresql","title":"Sauvegarder PostgreSQL","text":"<pre><code># Cr\u00e9er sauvegarde\ndocker exec pennylane_postgres pg_dump -U pennylane_user pennylane_data &gt; backup_$(date +%Y%m%d).sql\n\n# Restaurer sauvegarde\ndocker exec -i pennylane_postgres psql -U pennylane_user pennylane_data &lt; backup_20250107.sql\n</code></pre>"},{"location":"guide-utilisateur/#sauvegarder-configuration","title":"Sauvegarder configuration","text":"<pre><code># ATTENTION : Ne pas commiter .env sur GitHub !\ncp .env .env.backup\n</code></pre>"},{"location":"guide-utilisateur/#mise-a-jour-du-code","title":"Mise \u00e0 jour du code","text":"<pre><code># R\u00e9cup\u00e9rer derni\u00e8res modifications\ngit pull origin main\n\n# R\u00e9installer d\u00e9pendances si n\u00e9cessaire\npip install -r requirements.txt --upgrade\n\n# Red\u00e9marrer PostgreSQL si docker-compose modifi\u00e9\ndocker-compose down\ndocker-compose up -d\n</code></pre>"},{"location":"guide-utilisateur/#depannage","title":"\ud83d\udc1b D\u00e9pannage","text":""},{"location":"guide-utilisateur/#erreurs-frequentes","title":"Erreurs fr\u00e9quentes","text":""},{"location":"guide-utilisateur/#1-variable-denvironnement-pennylane_api_key-requise","title":"1. \"Variable d'environnement PENNYLANE_API_KEY requise\"","text":"<p>Cause : Fichier <code>.env</code> manquant ou mal configur\u00e9</p> <p>Solution : <pre><code>cp .env.example .env\nnotepad .env  # Configurer PENNYLANE_API_KEY\n</code></pre></p>"},{"location":"guide-utilisateur/#2-erreur-connexion-postgresql","title":"2. \"Erreur connexion PostgreSQL\"","text":"<p>Cause : Docker pas d\u00e9marr\u00e9 ou conteneur arr\u00eat\u00e9</p> <p>Solution : <pre><code>docker ps  # V\u00e9rifier conteneurs actifs\ndocker-compose restart postgres\n</code></pre></p>"},{"location":"guide-utilisateur/#3-rate-limit-depasse-429","title":"3. \"Rate limit d\u00e9pass\u00e9 (429)\"","text":"<p>Cause : Trop de requ\u00eates API en peu de temps</p> <p>Solution : Le script g\u00e8re automatiquement, attendre quelques secondes.</p> <p>Si probl\u00e8me persiste, r\u00e9duire dans <code>.env</code> : <pre><code>PENNYLANE_RATE_LIMIT=3.0\n</code></pre></p>"},{"location":"guide-utilisateur/#4-aucune-donnee-extraite","title":"4. \"Aucune donn\u00e9e extraite\"","text":"<p>Cause : Endpoint API incorrect ou pas de nouvelles donn\u00e9es</p> <p>Solution : <pre><code># Forcer extraction compl\u00e8te\npython main.py full\n\n# V\u00e9rifier logs\ntype logs\\pennylane_etl.log\n</code></pre></p>"},{"location":"guide-utilisateur/#reinitialisation-complete","title":"R\u00e9initialisation compl\u00e8te","text":"<pre><code># 1. Arr\u00eater tout\ndocker-compose down -v  # -v supprime volumes (donn\u00e9es)\n\n# 2. Nettoyer logs\nrm -rf logs/*  # Linux/Mac\ndel /q logs\\*  # Windows\n\n# 3. Red\u00e9marrer\ndocker-compose up -d\ncd src &amp;&amp; python main.py full\n</code></pre>"},{"location":"guide-utilisateur/#evolutions-futures","title":"\ud83d\udd2e \u00c9volutions futures","text":""},{"location":"guide-utilisateur/#version-actuelle-10","title":"Version actuelle : 1.0","text":"<ul> <li>[x] Extraction API Pennylane</li> <li>[x] Stockage PostgreSQL</li> <li>[x] Planificateur 10 min</li> <li>[x] Gestion .env s\u00e9curis\u00e9e</li> <li>[x] Documentation compl\u00e8te</li> </ul>"},{"location":"guide-utilisateur/#prochaines-versions","title":"Prochaines versions","text":""},{"location":"guide-utilisateur/#v11-optimisations","title":"v1.1 - Optimisations","text":"<ul> <li>[ ] Parall\u00e9lisation extraction multi-endpoints</li> <li>[ ] Cache local pour r\u00e9duire appels API</li> <li>[ ] Notifications email en cas d'erreur</li> </ul>"},{"location":"guide-utilisateur/#v12-transformations-avancees","title":"v1.2 - Transformations avanc\u00e9es","text":"<ul> <li>[ ] Biblioth\u00e8que transformations r\u00e9utilisables</li> <li>[ ] Calculs analytiques pr\u00e9d\u00e9finis (CA, marges, etc.)</li> <li>[ ] D\u00e9tection anomalies</li> </ul>"},{"location":"guide-utilisateur/#v13-dashboards","title":"v1.3 - Dashboards","text":"<ul> <li>[ ] Dashboard Streamlit int\u00e9gr\u00e9</li> <li>[ ] M\u00e9triques temps r\u00e9el</li> <li>[ ] Alertes personnalisables</li> </ul>"},{"location":"guide-utilisateur/#support","title":"\ud83d\udcde Support","text":""},{"location":"guide-utilisateur/#documentation","title":"Documentation","text":"<ul> <li>README : README.md</li> <li>API Pennylane : pennylane.readme.io</li> </ul>"},{"location":"guide-utilisateur/#contribution","title":"Contribution","text":"<p>Issues et Pull Requests bienvenues : github.com/yves34690/Penny/issues</p> <p>\ud83d\udcdd Ce guide sera mis \u00e0 jour au fil des d\u00e9veloppements.</p> <p>Derni\u00e8re r\u00e9vision : 2025-10-07 par yves34690</p>"}]}